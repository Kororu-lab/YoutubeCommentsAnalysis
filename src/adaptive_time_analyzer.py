"""
Adaptive Time Analyzer Module
ì ì‘ì  ì‹œê°„ ë¶„ì„ ëª¨ë“ˆ - ë°ì´í„° ë¶„í¬ì— ë”°ë¼ ì›”ë³„/ì£¼ê°„ ë¶„ì„ ìë™ ì„ íƒ
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import os

class AdaptiveTimeAnalyzer:
    """ì ì‘ì  ì‹œê°„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, config):
        """
        ì´ˆê¸°í™”
        Args:
            config: AnalysisConfig ê°ì²´
        """
        self.config = config
        self.logger = self._setup_logger()
        
        # config.pyì˜ ì ì‘ì  ì‹œê°„ ë¶„í•  ì„¤ì • ì‚¬ìš©
        adaptive_config = config.ADAPTIVE_TIME_ANALYSIS
        self.adaptive_enabled = adaptive_config['enabled']
        self.high_ratio_threshold = adaptive_config['high_ratio_threshold']
        self.subdivision_levels = adaptive_config['subdivision_levels']
        self.min_comments_per_period = adaptive_config['min_comments_per_period']
        
        # ğŸ”§ ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ ì„¤ì • (í•˜ì´í¼íŒŒë¼ë¯¸í„°)
        self.min_time_unit = adaptive_config['min_time_unit']
        time_unit_config = adaptive_config['time_unit_configs'][self.min_time_unit]
        self.max_subdivision_depth = time_unit_config['max_subdivision_depth']
        self.subdivision_chain = time_unit_config['subdivision_chain']
        self.initial_level = time_unit_config['initial_level']
        
        self.logger.info(f"ğŸ”§ ì‹œê°„ ê°„ê²© ìµœì†Œ ë‹¨ìœ„: {self.min_time_unit}")
        self.logger.info(f"ğŸ”§ ì„¸ë¶„í™” ì²´ì¸: {' â†’ '.join(self.subdivision_chain)}")
        self.logger.info(f"ğŸ”§ ìµœëŒ€ ì„¸ë¶„í™” ê¹Šì´: {self.max_subdivision_depth}")
        
        # ê¸°ì¡´ ë¶„ì„ ê¸°ì¤€ ì„¤ì • (í˜¸í™˜ì„± ìœ ì§€)
        self.min_periods = 5  # ìµœì†Œ ë¶„ì„ ê¸°ê°„ ìˆ˜
        self.outlier_threshold = 0.1  # ì•„ì›ƒë¼ì´ì–´ ì„ê³„ê°’ (10ë¶„ìœ„ìˆ˜)
        self.weekly_merge_threshold = 50  # ì£¼ê°„ ë¶„ì„ì—ì„œ ë³‘í•©í•  ìµœì†Œ ëŒ“ê¸€ ìˆ˜
        self.absolute_min_threshold = 30  # ì ˆëŒ€ ìµœì†Œ ëŒ“ê¸€ ìˆ˜ (ì´ ë¯¸ë§Œì€ ì•„ì˜ˆ ì œì™¸)
        
    def _setup_logger(self):
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger(__name__)
        logger.setLevel(getattr(logging, self.config.LOGGING['level']))
        
        if not logger.handlers:
            handler = logging.FileHandler(self.config.LOGGING['file'], encoding='utf-8')
            formatter = logging.Formatter(self.config.LOGGING['format'])
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
    
    def _setup_korean_font_for_plot(self):
        """í”Œë¡¯ìš© í•œê¸€ í°íŠ¸ ì„¤ì • ê°•í™”"""
        try:
            import matplotlib.font_manager as fm
            from matplotlib import rcParams
            import platform
            
            # 1. ì‹œìŠ¤í…œë³„ í•œêµ­ì–´ í°íŠ¸ ê²½ë¡œ í™•ì¥
            font_paths = []
            
            system = platform.system()
            if system == "Darwin":  # macOS
                font_paths.extend([
                    '/System/Library/Fonts/AppleGothic.ttf',
                    '/System/Library/Fonts/AppleSDGothicNeo.ttc',
                    '/Library/Fonts/NanumGothic.ttf',
                    '/Library/Fonts/NanumBarunGothic.ttf',
                    os.path.join(self.config.BASE_DIR, 'fonts', 'AppleGothic.ttf')
                ])
            elif system == "Linux":  # Ubuntu/Linux
                font_paths.extend([
                    '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
                    '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',
                    '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf',
                    '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
                    os.path.join(self.config.BASE_DIR, 'fonts', 'NanumGothic.ttf')
                ])
            elif system == "Windows":  # Windows
                font_paths.extend([
                    'C:/Windows/Fonts/malgun.ttf',
                    'C:/Windows/Fonts/gulim.ttc',
                    'C:/Windows/Fonts/batang.ttc',
                    os.path.join(self.config.BASE_DIR, 'fonts', 'malgun.ttf')
                ])
            
            # 2. ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ íŒŒì¼ ì°¾ê¸°
            available_font_path = None
            for path in font_paths:
                if os.path.exists(path):
                    available_font_path = path
                    break
            
            # 3. í°íŠ¸ ì„¤ì •
            if available_font_path:
                try:
                    # matplotlib ìºì‹œ ì •ë¦¬
                    import shutil
                    cache_dir = os.path.expanduser('~/.cache/matplotlib')
                    if os.path.exists(cache_dir):
                        try:
                            shutil.rmtree(cache_dir)
                        except:
                            pass
                    
                    # í°íŠ¸ ë“±ë¡
                    try:
                        fm.fontManager.addfont(available_font_path)
                    except:
                        pass
                    
                    # í°íŠ¸ ì†ì„± ê°€ì ¸ì˜¤ê¸°
                    font_prop = fm.FontProperties(fname=available_font_path)
                    font_name = font_prop.get_name()
                    
                    # matplotlib ì„¤ì • ì´ˆê¸°í™” í›„ ì¬ì„¤ì •
                    plt.rcdefaults()
                    
                    # ê°•ë ¥í•œ í°íŠ¸ ì„¤ì •
                    rcParams['font.family'] = font_name
                    rcParams['font.sans-serif'] = [font_name, 'DejaVu Sans', 'Arial Unicode MS']
                    rcParams['axes.unicode_minus'] = False
                    rcParams['font.size'] = 10
                    
                    plt.rcParams['font.family'] = font_name
                    plt.rcParams['font.sans-serif'] = [font_name, 'DejaVu Sans', 'Arial Unicode MS']
                    plt.rcParams['axes.unicode_minus'] = False
                    plt.rcParams['font.size'] = 10
                    
                    # í°íŠ¸ ìºì‹œ ì¬êµ¬ì„±
                    fm._rebuild()
                    
                    self.logger.info(f"âœ… í•œê¸€ í°íŠ¸ íŒŒì¼ ì„¤ì • ì™„ë£Œ: {font_name} ({available_font_path})")
                    return
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ í°íŠ¸ íŒŒì¼ ì„¤ì • ì‹¤íŒ¨: {e}")
            
            # 4. ì‹œìŠ¤í…œ í°íŠ¸ ëª©ë¡ì—ì„œ í•œêµ­ì–´ í°íŠ¸ ì°¾ê¸°
            available_fonts = [f.name for f in fm.fontManager.ttflist]
            korean_fonts = [
                'AppleGothic', 'Apple Gothic', 'AppleSDGothicNeo-Regular',
                'NanumGothic', 'Nanum Gothic', 'NanumBarunGothic',
                'Malgun Gothic', 'Microsoft YaHei', 'SimHei',
                'Gulim', 'Batang', 'Dotum'
            ]
                
            found_font = None
            for korean_font in korean_fonts:
                if korean_font in available_fonts:
                    found_font = korean_font
                    break
            
            if found_font:
                plt.rcdefaults()
                rcParams['font.family'] = found_font
                rcParams['font.sans-serif'] = [found_font, 'DejaVu Sans']
                rcParams['axes.unicode_minus'] = False
                rcParams['font.size'] = 10
                
                plt.rcParams['font.family'] = found_font
                plt.rcParams['font.sans-serif'] = [found_font, 'DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                plt.rcParams['font.size'] = 10
                
                self.logger.info(f"âœ… ì‹œìŠ¤í…œ í•œê¸€ í°íŠ¸ ì‚¬ìš©: {found_font}")
            else:
                # 5. ìµœí›„ ìˆ˜ë‹¨: ìœ ë‹ˆì½”ë“œ ì§€ì› í°íŠ¸
                plt.rcdefaults()
                rcParams['font.family'] = 'DejaVu Sans'
                rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'Liberation Sans']
                rcParams['axes.unicode_minus'] = False
                rcParams['font.size'] = 10
                
                plt.rcParams['font.family'] = 'DejaVu Sans'
                plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'Liberation Sans']
                plt.rcParams['axes.unicode_minus'] = False
                plt.rcParams['font.size'] = 10
                
                self.logger.warning("âš ï¸ í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ DejaVu Sans ì‚¬ìš©")
                    
        except Exception as e:
            self.logger.error(f"âŒ í”Œë¡¯ìš© í°íŠ¸ ì„¤ì • ì‹¤íŒ¨: {str(e)}")
            # ì•ˆì „í•œ ê¸°ë³¸ ì„¤ì •
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False
    
    def analyze_time_distribution(self, df: pd.DataFrame, date_column: str = 'date') -> Dict:
        """
        ì‹œê°„ ë¶„í¬ ë¶„ì„
        Args:
            df: ë°ì´í„°í”„ë ˆì„
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
        Returns:
            ë¶„í¬ ë¶„ì„ ê²°ê³¼
        """
        try:
            self.logger.info("ğŸ“Š ì‹œê°„ ë¶„í¬ ë¶„ì„ ì‹œì‘")
            
            # ë‚ ì§œ ì»¬ëŸ¼ í™•ì¸ ë° ë³€í™˜
            if date_column not in df.columns:
                self.logger.error(f"âŒ ë‚ ì§œ ì»¬ëŸ¼ '{date_column}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ë‚ ì§œ í˜•ì‹ í†µì¼
            df[date_column] = pd.to_datetime(df[date_column], errors='coerce')
            df = df.dropna(subset=[date_column])
            
            if len(df) == 0:
                self.logger.error("âŒ ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ê¸°ë³¸ í†µê³„
            date_range = {
                'start': df[date_column].min(),
                'end': df[date_column].max(),
                'total_days': (df[date_column].max() - df[date_column].min()).days + 1
            }
            
            self.logger.info(f"ğŸ“… ë¶„ì„ ê¸°ê°„: {date_range['start'].strftime('%Y-%m-%d')} ~ {date_range['end'].strftime('%Y-%m-%d')} ({date_range['total_days']}ì¼)")
            
            # ì›”ë³„ ë¶„í¬ ë¶„ì„
            monthly_dist = self._analyze_monthly_distribution(df, date_column)
            
            # ì£¼ê°„ ë¶„í¬ ë¶„ì„
            weekly_dist = self._analyze_weekly_distribution(df, date_column)
            
            # ì¼ë³„ ë¶„í¬ ë¶„ì„
            daily_dist = self._analyze_daily_distribution(df, date_column)
            
            # ìµœì  ë¶„ì„ ë‹¨ìœ„ ê²°ì •
            optimal_unit = self._determine_optimal_time_unit(monthly_dist, weekly_dist, daily_dist)
            
            result = {
                'date_range': date_range,
                'total_comments': len(df),
                'monthly_distribution': monthly_dist,
                'weekly_distribution': weekly_dist,
                'daily_distribution': daily_dist,
                'optimal_time_unit': optimal_unit,
                'recommendation': self._generate_recommendation(optimal_unit, monthly_dist, weekly_dist)
            }
            
            self.logger.info(f"âœ… ì‹œê°„ ë¶„í¬ ë¶„ì„ ì™„ë£Œ: ìµœì  ë‹¨ìœ„ = {optimal_unit}")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°„ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def _analyze_monthly_distribution(self, df: pd.DataFrame, date_column: str) -> Dict:
        """ì›”ë³„ ë¶„í¬ ë¶„ì„"""
        try:
            # ì›”ë³„ ê·¸ë£¹í™”
            df['year_month'] = df[date_column].dt.to_period('M')
            monthly_counts = df.groupby('year_month').size()
            
            if len(monthly_counts) == 0:
                return {'valid': False, 'reason': 'ì›”ë³„ ë°ì´í„° ì—†ìŒ'}
            
            # í†µê³„ ê³„ì‚°
            stats = {
                'count': len(monthly_counts),
                'mean': monthly_counts.mean(),
                'median': monthly_counts.median(),
                'std': monthly_counts.std(),
                'min': monthly_counts.min(),
                'max': monthly_counts.max(),
                'q10': monthly_counts.quantile(0.1),
                'q90': monthly_counts.quantile(0.9)
            }
            
            # ë¶„í¬ í’ˆì§ˆ í‰ê°€
            cv = stats['std'] / stats['mean'] if stats['mean'] > 0 else float('inf')  # ë³€ë™ê³„ìˆ˜
            outlier_ratio = len(monthly_counts[monthly_counts < stats['q10']]) / len(monthly_counts)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            valid = (
                stats['count'] >= self.min_periods and
                stats['min'] >= self.min_comments_per_period and
                cv < 2.0 and  # ë³€ë™ê³„ìˆ˜ê°€ ë„ˆë¬´ í¬ì§€ ì•ŠìŒ
                outlier_ratio < 0.3  # ì•„ì›ƒë¼ì´ì–´ê°€ 30% ë¯¸ë§Œ
            )
            
            return {
                'valid': valid,
                'stats': stats,
                'coefficient_of_variation': cv,
                'outlier_ratio': outlier_ratio,
                'data': monthly_counts.to_dict(),
                'periods': [str(period) for period in monthly_counts.index]
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì›”ë³„ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {'valid': False, 'reason': str(e)}
    
    def _analyze_weekly_distribution(self, df: pd.DataFrame, date_column: str) -> Dict:
        """ì£¼ê°„ ë¶„í¬ ë¶„ì„"""
        try:
            # ì£¼ê°„ ê·¸ë£¹í™” (ISO ì£¼ì°¨)
            df['year_week'] = df[date_column].dt.to_period('W')
            weekly_counts = df.groupby('year_week').size()
            
            if len(weekly_counts) == 0:
                return {'valid': False, 'reason': 'ì£¼ê°„ ë°ì´í„° ì—†ìŒ'}
            
            # í†µê³„ ê³„ì‚°
            stats = {
                'count': len(weekly_counts),
                'mean': weekly_counts.mean(),
                'median': weekly_counts.median(),
                'std': weekly_counts.std(),
                'min': weekly_counts.min(),
                'max': weekly_counts.max(),
                'q10': weekly_counts.quantile(0.1),
                'q90': weekly_counts.quantile(0.9)
            }
            
            # ë¶„í¬ í’ˆì§ˆ í‰ê°€
            cv = stats['std'] / stats['mean'] if stats['mean'] > 0 else float('inf')
            outlier_ratio = len(weekly_counts[weekly_counts < stats['q10']]) / len(weekly_counts)
            low_data_weeks = len(weekly_counts[weekly_counts < self.weekly_merge_threshold])
            
            # ìœ íš¨ì„± ê²€ì‚¬
            valid = (
                stats['count'] >= self.min_periods * 4 and  # ì›”ë³„ë³´ë‹¤ 4ë°° ë§ì€ ê¸°ê°„ í•„ìš”
                stats['median'] >= self.min_comments_per_period / 4 and  # ì£¼ê°„ì€ ì›”ë³„ì˜ 1/4 ìˆ˜ì¤€
                cv < 3.0 and  # ì£¼ê°„ì€ ë³€ë™ì´ ë” í´ ìˆ˜ ìˆìŒ
                outlier_ratio < 0.4 and  # ì•„ì›ƒë¼ì´ì–´ í—ˆìš©ë„ ë†’ì„
                low_data_weeks / len(weekly_counts) < 0.5  # ì €ë°ì´í„° ì£¼ê°„ì´ 50% ë¯¸ë§Œ
            )
            
            return {
                'valid': valid,
                'stats': stats,
                'coefficient_of_variation': cv,
                'outlier_ratio': outlier_ratio,
                'low_data_weeks': low_data_weeks,
                'low_data_ratio': low_data_weeks / len(weekly_counts),
                'data': weekly_counts.to_dict(),
                'periods': [str(period) for period in weekly_counts.index]
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì£¼ê°„ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {'valid': False, 'reason': str(e)}
    
    def _analyze_daily_distribution(self, df: pd.DataFrame, date_column: str) -> Dict:
        """ì¼ë³„ ë¶„í¬ ë¶„ì„ (ì°¸ê³ ìš©)"""
        try:
            # ì¼ë³„ ê·¸ë£¹í™”
            df['date_only'] = df[date_column].dt.date
            daily_counts = df.groupby('date_only').size()
            
            if len(daily_counts) == 0:
                return {'valid': False, 'reason': 'ì¼ë³„ ë°ì´í„° ì—†ìŒ'}
            
            # ê¸°ë³¸ í†µê³„ë§Œ ê³„ì‚° (ì¼ë³„ ë¶„ì„ì€ ë„ˆë¬´ ì„¸ë¶„í™”ë˜ì–´ ì£¼ë¡œ ì°¸ê³ ìš©)
            stats = {
                'count': len(daily_counts),
                'mean': daily_counts.mean(),
                'median': daily_counts.median(),
                'std': daily_counts.std(),
                'min': daily_counts.min(),
                'max': daily_counts.max()
            }
            
            return {
                'valid': False,  # ì¼ë³„ ë¶„ì„ì€ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                'stats': stats,
                'reason': 'ì¼ë³„ ë¶„ì„ì€ ë„ˆë¬´ ì„¸ë¶„í™”ë¨'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì¼ë³„ ë¶„í¬ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {'valid': False, 'reason': str(e)}
    
    def _determine_optimal_time_unit(self, monthly_dist: Dict, weekly_dist: Dict, daily_dist: Dict) -> str:
        """ìµœì  ì‹œê°„ ë‹¨ìœ„ ê²°ì • (ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ ì œì•½ ì ìš©)"""
        try:
            # ğŸ”§ ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ ì œì•½ ì ìš©
            self.logger.info(f"ğŸ”§ ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ ì œì•½: {self.min_time_unit}")
            
            # ìœ íš¨ì„± ê²€ì‚¬
            monthly_valid = monthly_dist.get('valid', False)
            weekly_valid = weekly_dist.get('valid', False)
            daily_valid = daily_dist.get('valid', False)
            
            # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            monthly_score = self._calculate_distribution_quality_score(monthly_dist) if monthly_valid else 0
            weekly_score = self._calculate_distribution_quality_score(weekly_dist) if weekly_valid else 0
            daily_score = self._calculate_distribution_quality_score(daily_dist) if daily_valid else 0
            
            self.logger.info(f"ğŸ“Š ë¶„í¬ í’ˆì§ˆ ì ìˆ˜ - ì›”ë³„: {monthly_score:.2f}, ì£¼ê°„: {weekly_score:.2f}, ì¼ë³„: {daily_score:.2f}")
            
            # ë°ì´í„° ë°€ë„ ë¶„ì„
            monthly_density = self._analyze_data_density(monthly_dist)
            weekly_density = self._analyze_data_density(weekly_dist)
            
            # ğŸ”§ ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ì— ë”°ë¥¸ ê²°ì • ë¡œì§
            if self.min_time_unit == 'monthly':
                # ì›”ë³„ë§Œ í—ˆìš©
                if monthly_valid and monthly_score >= 0.4:
                    self.logger.info("ğŸ“… ì›”ë³„ ë¶„ì„ ì ìš© (ìµœì†Œ ë‹¨ìœ„ ì œì•½)")
                    return 'monthly'
                else:
                    self.logger.warning("âš ï¸ ì›”ë³„ ë¶„ì„ì´ ë¶€ì ì ˆí•˜ì§€ë§Œ ìµœì†Œ ë‹¨ìœ„ ì œì•½ìœ¼ë¡œ ê°•ì œ ì ìš©")
                    return 'monthly'
                    
            elif self.min_time_unit == 'weekly':
                # ì›”ë³„ ë˜ëŠ” ì£¼ê°„ í—ˆìš©
                if monthly_valid and monthly_score >= 0.7:
                    # ì›”ë³„ ë¶„ì„ì´ ì¶©ë¶„íˆ ì¢‹ì€ ê²½ìš°
                    if monthly_density['high_density_ratio'] > 0.3:
                        # ê³ ë°€ë„ êµ¬ê°„ì´ 30% ì´ìƒì´ë©´ ì£¼ê°„ìœ¼ë¡œ ì„¸ë¶„í™”
                        if weekly_valid and weekly_score >= 0.5:
                            self.logger.info("ğŸ“… ì£¼ê°„ ë¶„ì„ ì ìš© (ê³ ë°€ë„ êµ¬ê°„ ì„¸ë¶„í™”)")
                            return 'weekly'
                        else:
                            self.logger.info("ğŸ“… ì›”ë³„ ë¶„ì„ ì ìš© (ì£¼ê°„ ë¶„ì„ ë¶ˆê°€)")
                            return 'monthly'
                    else:
                        self.logger.info("ğŸ“… ì›”ë³„ ë¶„ì„ ì ìš©")
                        return 'monthly'
                elif weekly_valid and weekly_score >= 0.6:
                    # ì£¼ê°„ ë¶„ì„ì´ ì ì ˆí•œ ê²½ìš°
                    self.logger.info("ğŸ“… ì£¼ê°„ ë¶„ì„ ì ìš©")
                    return 'weekly'
                elif monthly_valid and monthly_score >= 0.4:
                    # ì›”ë³„ì´ ìµœì†Œí•œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
                    self.logger.info("ğŸ“… ì›”ë³„ ë¶„ì„ ì ìš©")
                    return 'monthly'
                elif weekly_valid:
                    # ì£¼ê°„ì´ë¼ë„ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
                    self.logger.info("ğŸ“… ì£¼ê°„ ë¶„ì„ ì ìš©")
                    return 'weekly'
                else:
                    # ìµœì†Œ ë‹¨ìœ„ ì œì•½ìœ¼ë¡œ ì£¼ê°„ ê°•ì œ ì ìš©
                    self.logger.warning("âš ï¸ ì£¼ê°„ ë¶„ì„ì´ ë¶€ì ì ˆí•˜ì§€ë§Œ ìµœì†Œ ë‹¨ìœ„ ì œì•½ìœ¼ë¡œ ê°•ì œ ì ìš©")
                    return 'weekly'
                    
            elif self.min_time_unit == 'daily':
                # ëª¨ë“  ë‹¨ìœ„ í—ˆìš© (ê¸°ì¡´ ë¡œì§)
                if monthly_valid and monthly_score >= 0.7:
                    # ì›”ë³„ ë¶„ì„ì´ ì¶©ë¶„íˆ ì¢‹ì€ ê²½ìš°
                    if monthly_density['high_density_ratio'] > 0.3:
                        # ê³ ë°€ë„ êµ¬ê°„ì´ 30% ì´ìƒì´ë©´ í˜¼í•© ë°©ì‹ (ì£¼ê°„/ì¼ë³„ ì„¸ë¶„í™”)
                        self.logger.info("ğŸ“… ì›”ë³„ ë¶„ì„ì´ ìš°ìˆ˜í•˜ë‚˜ ê³ ë°€ë„ êµ¬ê°„ì´ ë§ì•„ í˜¼í•© ë¶„ì„ì„ ì ìš©í•©ë‹ˆë‹¤.")
                        return 'hybrid'
                    else:
                        self.logger.info("ğŸ“… ì›”ë³„ ë¶„ì„ì´ ì í•©í•©ë‹ˆë‹¤.")
                    return 'monthly'
                elif weekly_valid and weekly_score >= 0.6:
                    # ì£¼ê°„ ë¶„ì„ì´ ì ì ˆí•œ ê²½ìš°
                    self.logger.info("ğŸ“… ì£¼ê°„ ë¶„ì„ì´ ì í•©í•©ë‹ˆë‹¤.")
                    return 'weekly'
                elif monthly_valid and monthly_score >= 0.4:
                    # ì›”ë³„ì´ ìµœì†Œí•œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
                    self.logger.info("ğŸ“… ì›”ë³„ ë¶„ì„ì´ ì ì ˆí•©ë‹ˆë‹¤.")
                    return 'monthly'
                elif weekly_valid:
                    # ì£¼ê°„ì´ë¼ë„ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
                    self.logger.info("ğŸ“… ì£¼ê°„ ë¶„ì„ì„ ì ìš©í•©ë‹ˆë‹¤.")
                    return 'weekly'
                elif daily_valid:
                    # ì¼ë³„ë§Œ ê°€ëŠ¥í•œ ê²½ìš°
                    self.logger.info("ğŸ“… ì¼ë³„ ë¶„ì„ì„ ì ìš©í•©ë‹ˆë‹¤.")
                    return 'daily'
                else:
                    # ëª¨ë“  ë‹¨ìœ„ê°€ ë¶€ì ì ˆí•œ ê²½ìš° í˜¼í•© ë°©ì‹ìœ¼ë¡œ ìµœëŒ€í•œ í™œìš©
                    self.logger.warning("âš ï¸ ëª¨ë“  ë‹¨ìœ„ê°€ ë¶€ì ì ˆí•˜ì—¬ í˜¼í•© ë¶„ì„ì„ ê°•ì œ ì ìš©í•©ë‹ˆë‹¤.")
                    return 'hybrid'
            
            # ê¸°ë³¸ê°’ (ì„¤ì • ì˜¤ë¥˜ ì‹œ)
            self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ìµœì†Œ ì‹œê°„ ë‹¨ìœ„: {self.min_time_unit}, ê¸°ë³¸ê°’ ì ìš©")
            return self.min_time_unit if self.min_time_unit in ['monthly', 'weekly', 'daily'] else 'weekly'
            
        except Exception as e:
            self.logger.error(f"âŒ ìµœì  ì‹œê°„ ë‹¨ìœ„ ê²°ì • ì‹¤íŒ¨: {str(e)}")
            return self.min_time_unit if hasattr(self, 'min_time_unit') else 'weekly'  # ì•ˆì „í•œ ê¸°ë³¸ê°’
    
    def _calculate_distribution_quality_score(self, dist: Dict) -> float:
        """ë¶„í¬ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0~1)"""
        try:
            if not dist.get('valid', False):
                return 0.0
            
            stats = dist.get('stats', {})
            if not stats:
                return 0.0
            
            # ê¸°ë³¸ ì ìˆ˜ (ìœ íš¨í•œ ë¶„í¬ë©´ 0.5)
            score = 0.5
            
            # 1. ê¸°ê°„ ìˆ˜ ì ìˆ˜ (ë” ë§ì€ ê¸°ê°„ì´ ì¢‹ìŒ)
            period_count = stats.get('count', 0)
            if period_count >= 6:
                score += 0.2
            elif period_count >= 3:
                score += 0.1
            
            # 2. ë³€ë™ê³„ìˆ˜ ì ìˆ˜ (ì ë‹¹í•œ ë³€ë™ì´ ì¢‹ìŒ)
            cv = dist.get('coefficient_of_variation', float('inf'))
            if 0.3 <= cv <= 1.5:
                score += 0.2
            elif cv < 2.0:
                score += 0.1
            
            # 3. ì•„ì›ƒë¼ì´ì–´ ë¹„ìœ¨ ì ìˆ˜ (ì ì€ ì•„ì›ƒë¼ì´ì–´ê°€ ì¢‹ìŒ)
            outlier_ratio = dist.get('outlier_ratio', 1.0)
            if outlier_ratio < 0.2:
                score += 0.1
            elif outlier_ratio < 0.4:
                score += 0.05
            
            # 4. ìµœì†Œê°’ ì ìˆ˜ (ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì¢‹ìŒ)
            min_count = stats.get('min', 0)
            if min_count >= self.min_comments_per_period * 2:
                score += 0.1
            elif min_count >= self.min_comments_per_period:
                score += 0.05
            
            return min(score, 1.0)
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë¶„í¬ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _analyze_data_density(self, dist: Dict) -> Dict:
        """ë°ì´í„° ë°€ë„ ë¶„ì„ (ë¹„ìœ¨ ê¸°ë°˜)"""
        try:
            if not dist.get('valid', False):
                return {'high_density_ratio': 0, 'density_analysis': 'invalid'}
            
            stats = dist.get('stats', {})
            data = dist.get('data', {})
            
            if not stats or not data:
                return {'high_density_ratio': 0, 'density_analysis': 'no_data'}
            
            # ì „ì²´ ëŒ“ê¸€ ìˆ˜ ê³„ì‚°
            total_comments = sum(data.values())
            
            # ë¹„ìœ¨ ê¸°ë°˜ ê³ ë°€ë„ ì„ê³„ê°’ (ì „ì²´ì˜ 20% ì´ìƒì„ ì°¨ì§€í•˜ëŠ” ê¸°ê°„)
            high_density_comment_threshold = total_comments * 0.20
            
            # ë˜ëŠ” í‰ê· ì˜ 2ë°° ì´ìƒì¸ ê¸°ê°„ (ë‘˜ ì¤‘ ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì‚¬ìš©)
            mean_based_threshold = stats.get('mean', 0) * 2.0
            high_density_threshold = min(high_density_comment_threshold, mean_based_threshold)
            
            # ê³ ë°€ë„ êµ¬ê°„ ë¹„ìœ¨ ê³„ì‚°
            high_density_periods = [period for period, count in data.items() if count >= high_density_threshold]
            high_density_count = len(high_density_periods)
            total_periods = len(data)
            high_density_ratio = high_density_count / total_periods if total_periods > 0 else 0
            
            # ê³ ë°€ë„ êµ¬ê°„ì˜ ëŒ“ê¸€ ë¹„ìœ¨ ê³„ì‚°
            high_density_comments = sum(data[period] for period in high_density_periods)
            high_density_comment_ratio = high_density_comments / total_comments if total_comments > 0 else 0
            
            # ë°€ë„ ë¶„ì„ ê²°ê³¼ (ê¸°ê°„ ë¹„ìœ¨ê³¼ ëŒ“ê¸€ ë¹„ìœ¨ ëª¨ë‘ ê³ ë ¤)
            if high_density_ratio > 0.3 or high_density_comment_ratio > 0.5:
                density_analysis = 'high_concentration'  # ê³ ì§‘ì¤‘
            elif high_density_ratio > 0.15 or high_density_comment_ratio > 0.3:
                density_analysis = 'moderate_concentration'  # ì¤‘ê°„ì§‘ì¤‘
            else:
                density_analysis = 'low_concentration'  # ì €ì§‘ì¤‘
            
            return {
                'high_density_ratio': high_density_ratio,
                'high_density_comment_ratio': high_density_comment_ratio,
                'high_density_threshold': high_density_threshold,
                'high_density_periods': high_density_count,
                'high_density_periods_list': high_density_periods,
                'total_periods': total_periods,
                'total_comments': total_comments,
                'density_analysis': density_analysis
            }
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ ë°ì´í„° ë°€ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'high_density_ratio': 0, 'density_analysis': 'error'}
    
    def _generate_recommendation(self, optimal_unit: str, monthly_dist: Dict, weekly_dist: Dict) -> Dict:
        """ë¶„ì„ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        try:
            recommendations = {
                'time_unit': optimal_unit,
                'reasons': [],
                'warnings': [],
                'suggestions': []
            }
            
            if optimal_unit == 'monthly':
                recommendations['reasons'].append("ì›”ë³„ ë°ì´í„° ë¶„í¬ê°€ ì•ˆì •ì ì´ê³  ì¶©ë¶„í•©ë‹ˆë‹¤.")
                if monthly_dist.get('stats', {}).get('count', 0) < 12:
                    recommendations['warnings'].append("ë¶„ì„ ê¸°ê°„ì´ 1ë…„ ë¯¸ë§Œìœ¼ë¡œ ê³„ì ˆì„± ë¶„ì„ì— ì œí•œì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            elif optimal_unit == 'weekly':
                recommendations['reasons'].append("ì£¼ê°„ ë°ì´í„° ë¶„í¬ê°€ ì›”ë³„ë³´ë‹¤ ë” ì„¸ë°€í•œ ë¶„ì„ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.")
                recommendations['warnings'].append("ì£¼ê°„ ë¶„ì„ì€ ë…¸ì´ì¦ˆê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë‹ˆ íŠ¸ë Œë“œ í•´ì„ì— ì£¼ì˜í•˜ì„¸ìš”.")
                
                low_data_ratio = weekly_dist.get('low_data_ratio', 0)
                if low_data_ratio > 0.3:
                    recommendations['suggestions'].append(f"ë°ì´í„°ê°€ ì ì€ ì£¼ê°„({low_data_ratio:.1%})ì€ ì¸ì ‘ ì£¼ê°„ê³¼ ë³‘í•©ì„ ê³ ë ¤í•˜ì„¸ìš”.")
            
            elif optimal_unit == 'hybrid':
                recommendations['reasons'].append("ë°ì´í„° ë¶„í¬ê°€ ë¶ˆê· ë“±í•˜ì—¬ í˜¼í•© ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
                recommendations['suggestions'].append("ë°ì´í„°ê°€ ì¶©ë¶„í•œ ê¸°ê°„ì€ ì£¼ê°„ ë¶„ì„, ë¶€ì¡±í•œ ê¸°ê°„ì€ ì›”ë³„ ë¶„ì„ì„ ì ìš©í•©ë‹ˆë‹¤.")
            
            elif optimal_unit == 'monthly_forced':
                recommendations['warnings'].append("ë°ì´í„° ë¶„í¬ê°€ ì´ìƒì ì´ì§€ ì•Šì§€ë§Œ ì›”ë³„ ë¶„ì„ì„ ê°•ì œ ì ìš©í•©ë‹ˆë‹¤.")
                recommendations['suggestions'].append("ê²°ê³¼ í•´ì„ ì‹œ ë°ì´í„° í’ˆì§ˆ í•œê³„ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            
            return recommendations
            
        except Exception as e:
            self.logger.error(f"âŒ ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {'time_unit': optimal_unit, 'reasons': [], 'warnings': [], 'suggestions': []}
    
    def create_adaptive_subdivided_groups(self, df: pd.DataFrame, date_column: str = 'date') -> Dict:
        """
        ì ì‘ì  ì„¸ë¶„í™” ê·¸ë£¹ ìƒì„± (config.py ì„¤ì • ê¸°ë°˜)
        Args:
            df: ë°ì´í„°í”„ë ˆì„
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
        Returns:
            ì„¸ë¶„í™”ëœ ì‹œê°„ ê·¸ë£¹ ì •ë³´
        """
        try:
            if not self.adaptive_enabled:
                return self.create_adaptive_time_groups(df, 'monthly', date_column)
            
            self.logger.info("ğŸ”„ ì ì‘ì  ì‹œê°„ ì„¸ë¶„í™” ë¶„ì„ ì‹œì‘")
            
            # 1. ì›”ë³„ ê¸°ë³¸ ë¶„ì„
            monthly_groups = self._create_monthly_groups(df, date_column)
            
            # 2. ë¹„ìœ¨ ê¸°ë°˜ ì„¸ë¶„í™” í•„ìš”ì„± ê²€í† 
            total_comments = len(df)
            subdivisions_needed = []
            
            for period, group_data in monthly_groups.items():
                period_ratio = len(group_data) / total_comments
                if period_ratio >= self.high_ratio_threshold:
                    subdivisions_needed.append({
                        'period': period,
                        'ratio': period_ratio,
                        'count': len(group_data),
                        'data': group_data
                    })
            
            if not subdivisions_needed:
                self.logger.info("âœ… ì„¸ë¶„í™” ë¶ˆí•„ìš” - ì›”ë³„ ë¶„ì„ ì‚¬ìš©")
                return {'groups': monthly_groups, 'metadata': {'period_format': 'monthly'}}
            
            # 3. ì„¸ë¶„í™” ì‹¤í–‰
            final_groups = {'groups': {}, 'metadata': {}}
            
            for period, group_data in monthly_groups.items():
                period_ratio = len(group_data) / total_comments
                
                if period_ratio >= self.high_ratio_threshold:
                    # ì„¸ë¶„í™” í•„ìš”
                    subdivided = self._subdivide_period(group_data, period, date_column)
                    final_groups['groups'].update(subdivided['groups'])
                    self.logger.info(f"ğŸ“Š {period} ì„¸ë¶„í™”: {len(subdivided['groups'])}ê°œ êµ¬ê°„")
                else:
                    # ì„¸ë¶„í™” ë¶ˆí•„ìš”
                    start_date = group_data[date_column].min().strftime('%Y-%m-%d')
                    end_date = group_data[date_column].max().strftime('%Y-%m-%d')
                    period_key = f"{start_date} ~ {end_date}"
                    final_groups['groups'][period_key] = group_data
            
            # 4. ë©”íƒ€ë°ì´í„° ìƒì„±
            final_groups['metadata'] = {
                'total_periods': len(final_groups['groups']),
                'subdivisions_applied': len(subdivisions_needed),
                'high_ratio_threshold': self.high_ratio_threshold,
                'period_format': 'adaptive_subdivided'
            }
            
            self.logger.info(f"âœ… ì ì‘ì  ì„¸ë¶„í™” ì™„ë£Œ: {len(final_groups['groups'])}ê°œ êµ¬ê°„")
            return final_groups
            
        except Exception as e:
            self.logger.error(f"âŒ ì ì‘ì  ì„¸ë¶„í™” ì‹¤íŒ¨: {str(e)}")
            import traceback
            self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return self.create_adaptive_time_groups(df, 'monthly', date_column)
    
    def _subdivide_period(self, period_data: pd.DataFrame, period_name: str, date_column: str) -> Dict:
        """
        íŠ¹ì • ê¸°ê°„ì„ ì„¸ë¶„í™” (ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ ì œì•½ ì ìš©)
        Args:
            period_data: ê¸°ê°„ ë°ì´í„°
            period_name: ê¸°ê°„ëª…
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
        Returns:
            ì„¸ë¶„í™”ëœ ê·¸ë£¹
        """
        try:
            # ğŸ”§ ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ ì œì•½ì— ë”°ë¥¸ ì„¸ë¶„í™” ë¡œì§
            if self.min_time_unit == 'monthly':
                # ì›”ë³„ë§Œ í—ˆìš© - ì„¸ë¶„í™” ì•ˆí•¨
                start_date = period_data[date_column].min().strftime('%Y-%m-%d')
                end_date = period_data[date_column].max().strftime('%Y-%m-%d')
                period_key = f"{start_date} ~ {end_date}"
                self.logger.info(f"ğŸ”§ ì›”ë³„ ìµœì†Œ ë‹¨ìœ„ ì œì•½ìœ¼ë¡œ ì„¸ë¶„í™” ìƒëµ: {period_name}")
                return {'groups': {period_key: period_data}}
                
            elif self.min_time_unit == 'weekly':
                # ì£¼ë³„ê¹Œì§€ë§Œ í—ˆìš© - ì£¼ë³„ ì„¸ë¶„í™”ë§Œ ì‹œë„
                weekly_groups = self._create_weekly_groups_for_period(period_data, date_column)
                
                # ì£¼ë³„ ì„¸ë¶„í™”ê°€ íš¨ê³¼ì ì¸ì§€ í™•ì¸
                if len(weekly_groups['groups']) > 1:
                    # ê° ì£¼ì˜ ëŒ“ê¸€ ìˆ˜ê°€ ì¶©ë¶„í•œì§€ í™•ì¸
                    valid_weeks = {}
                    for week_key, week_data in weekly_groups['groups'].items():
                        if len(week_data) >= self.min_comments_per_period:
                            valid_weeks[week_key] = week_data
                    
                    if len(valid_weeks) > 1:
                        self.logger.info(f"ğŸ”§ ì£¼ë³„ ì„¸ë¶„í™” ì ìš©: {period_name} â†’ {len(valid_weeks)}ê°œ ì£¼ê°„")
                        return {'groups': valid_weeks}
                
                # ì£¼ë³„ ì„¸ë¶„í™”ê°€ íš¨ê³¼ì ì´ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ë°˜í™˜
                start_date = period_data[date_column].min().strftime('%Y-%m-%d')
                end_date = period_data[date_column].max().strftime('%Y-%m-%d')
                period_key = f"{start_date} ~ {end_date}"
                self.logger.info(f"ğŸ”§ ì£¼ë³„ ì„¸ë¶„í™” ë¶ˆê°€ë¡œ ì›”ë³„ ìœ ì§€: {period_name}")
                return {'groups': {period_key: period_data}}
                
            elif self.min_time_unit == 'daily':
                # ëª¨ë“  ë‹¨ìœ„ í—ˆìš© - ê¸°ì¡´ ë¡œì§
                # ì£¼ë³„ ì„¸ë¶„í™” ì‹œë„
                weekly_groups = self._create_weekly_groups_for_period(period_data, date_column)
                
                # ì£¼ë³„ ì„¸ë¶„í™”ê°€ íš¨ê³¼ì ì¸ì§€ í™•ì¸
                if len(weekly_groups['groups']) > 1:
                    # ê° ì£¼ì˜ ëŒ“ê¸€ ìˆ˜ê°€ ì¶©ë¶„í•œì§€ í™•ì¸
                    valid_weeks = {}
                    for week_key, week_data in weekly_groups['groups'].items():
                        if len(week_data) >= self.min_comments_per_period:
                            valid_weeks[week_key] = week_data
                    
                    if len(valid_weeks) > 1:
                        self.logger.info(f"ğŸ”§ ì£¼ë³„ ì„¸ë¶„í™” ì ìš©: {period_name} â†’ {len(valid_weeks)}ê°œ ì£¼ê°„")
                        return {'groups': valid_weeks}
                
                # ì£¼ë³„ ì„¸ë¶„í™”ê°€ íš¨ê³¼ì ì´ì§€ ì•Šìœ¼ë©´ ì¼ë³„ ì‹œë„
                daily_groups = self._create_daily_groups_for_period(period_data, date_column)
                
                if len(daily_groups['groups']) > 1:
                    valid_days = {}
                    for day_key, day_data in daily_groups['groups'].items():
                        if len(day_data) >= self.min_comments_per_period:
                            valid_days[day_key] = day_data
                    
                    if len(valid_days) > 1:
                        self.logger.info(f"ğŸ”§ ì¼ë³„ ì„¸ë¶„í™” ì ìš©: {period_name} â†’ {len(valid_days)}ê°œ ì¼ê°„")
                        return {'groups': valid_days}
                
                # ì„¸ë¶„í™”ê°€ ë¶ˆê°€ëŠ¥í•˜ë©´ ì›ë³¸ ë°˜í™˜
                start_date = period_data[date_column].min().strftime('%Y-%m-%d')
                end_date = period_data[date_column].max().strftime('%Y-%m-%d')
                period_key = f"{start_date} ~ {end_date}"
                self.logger.info(f"ğŸ”§ ì„¸ë¶„í™” ë¶ˆê°€ë¡œ ì›”ë³„ ìœ ì§€: {period_name}")
                return {'groups': {period_key: period_data}}
            
            # ê¸°ë³¸ê°’ (ì„¤ì • ì˜¤ë¥˜ ì‹œ)
            start_date = period_data[date_column].min().strftime('%Y-%m-%d')
            end_date = period_data[date_column].max().strftime('%Y-%m-%d')
            period_key = f"{start_date} ~ {end_date}"
            self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ìµœì†Œ ì‹œê°„ ë‹¨ìœ„: {self.min_time_unit}, ì›”ë³„ ìœ ì§€")
            return {'groups': {period_key: period_data}}
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ê°„ ì„¸ë¶„í™” ì‹¤íŒ¨: {str(e)}")
            return {'groups': {period_name: period_data}}
    
    def _create_weekly_groups_for_period(self, period_data: pd.DataFrame, date_column: str) -> Dict:
        """íŠ¹ì • ê¸°ê°„ì˜ ì£¼ë³„ ê·¸ë£¹ ìƒì„±"""
        try:
            period_data = period_data.copy()
            period_data['week'] = period_data[date_column].dt.strftime('%Y-W%U')
            
            groups = {}
            for week, group in period_data.groupby('week'):
                start_date = group[date_column].min().strftime('%Y-%m-%d')
                end_date = group[date_column].max().strftime('%Y-%m-%d')
                week_key = f"{start_date} ~ {end_date}"
                groups[week_key] = group.drop('week', axis=1)
            
            return {'groups': groups}
            
        except Exception as e:
            self.logger.error(f"âŒ ì£¼ë³„ ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {'groups': {}}
    
    def _create_daily_groups_for_period(self, period_data: pd.DataFrame, date_column: str) -> Dict:
        """íŠ¹ì • ê¸°ê°„ì˜ ì¼ë³„ ê·¸ë£¹ ìƒì„±"""
        try:
            period_data = period_data.copy()
            period_data['day'] = period_data[date_column].dt.strftime('%Y-%m-%d')
            
            groups = {}
            for day, group in period_data.groupby('day'):
                groups[day] = group.drop('day', axis=1)
            
            return {'groups': groups}
            
        except Exception as e:
            self.logger.error(f"âŒ ì¼ë³„ ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {'groups': {}}

    def create_adaptive_time_groups(self, df: pd.DataFrame, optimal_unit: str, date_column: str = 'date') -> Dict:
        """
        ì ì‘ì  ì‹œê°„ ê·¸ë£¹ ìƒì„±
        Args:
            df: ë°ì´í„°í”„ë ˆì„
            optimal_unit: ìµœì  ì‹œê°„ ë‹¨ìœ„
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
        Returns:
            ì‹œê°„ ê·¸ë£¹ë³„ ë°ì´í„°
        """
        try:
            self.logger.info(f"ğŸ”„ {optimal_unit} ê¸°ì¤€ìœ¼ë¡œ ì‹œê°„ ê·¸ë£¹ ìƒì„± ì‹œì‘")
            
            # ë‚ ì§œ ì»¬ëŸ¼ í™•ì¸ ë° ë³€í™˜
            df[date_column] = pd.to_datetime(df[date_column], errors='coerce')
            df = df.dropna(subset=[date_column])
            
            if optimal_unit == 'monthly' or optimal_unit == 'monthly_forced':
                groups = self._create_monthly_groups(df, date_column)
                return {'groups': groups, 'metadata': {'period_format': 'monthly'}}
            
            elif optimal_unit == 'weekly':
                groups = self._create_weekly_groups(df, date_column)
                return {'groups': groups, 'metadata': {'period_format': 'weekly'}}
            
            elif optimal_unit == 'hybrid':
                groups = self._create_adaptive_hybrid_groups(df, date_column)
                return {'groups': groups, 'metadata': {'period_format': 'hybrid'}}
            
            else:
                self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‹œê°„ ë‹¨ìœ„ '{optimal_unit}', ì›”ë³„ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                groups = self._create_monthly_groups(df, date_column)
                return {'groups': groups, 'metadata': {'period_format': 'monthly'}}
                
        except Exception as e:
            self.logger.error(f"âŒ ì ì‘ì  ì‹œê°„ ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {'groups': {}, 'metadata': {'period_format': 'error'}}
    
    def _create_monthly_groups(self, df: pd.DataFrame, date_column: str) -> Dict:
        """ì›”ë³„ ê·¸ë£¹ ìƒì„± (ìµœì†Œ ëŒ“ê¸€ ìˆ˜ í•„í„°ë§ ì ìš©)"""
        try:
            df['year_month'] = df[date_column].dt.to_period('M')
            monthly_groups = {}
            filtered_count = 0
            
            for period, group_df in df.groupby('year_month'):
                period_str = str(period)
                
                # ìµœì†Œ ëŒ“ê¸€ ìˆ˜ í™•ì¸
                if len(group_df) >= self.absolute_min_threshold:
                    monthly_groups[period_str] = group_df.drop('year_month', axis=1).copy()
                    self.logger.info(f"ğŸ“… {period_str}: {len(group_df)}ê°œ ëŒ“ê¸€ í¬í•¨")
                else:
                    filtered_count += 1
                    self.logger.info(f"âš ï¸ {period_str}: ëŒ“ê¸€ ìˆ˜ ë¶€ì¡±({len(group_df)}ê°œ < {self.absolute_min_threshold}ê°œ), ì œì™¸")
                
            if filtered_count > 0:
                self.logger.info(f"ğŸ“Š ì›”ë³„ ê·¸ë£¹ í•„í„°ë§: {filtered_count}ê°œ ì›” ì œì™¸ë¨")
                
            self.logger.info(f"ğŸ“… ì›”ë³„ ê·¸ë£¹ ìƒì„± ì™„ë£Œ: {len(monthly_groups)}ê°œ ì›” (í•„í„°ë§ ì ìš©)")
            return monthly_groups
            
        except Exception as e:
            self.logger.error(f"âŒ ì›”ë³„ ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _create_weekly_groups(self, df: pd.DataFrame, date_column: str) -> Dict:
        """ì£¼ê°„ ê·¸ë£¹ ìƒì„± (ì €ë°ì´í„° ì£¼ê°„ ë³‘í•© ë° ì ˆëŒ€ ìµœì†Œê°’ í•„í„°ë§)"""
        try:
            df['year_week'] = df[date_column].dt.to_period('W')
            weekly_counts = df.groupby('year_week').size()
            
            # ì €ë°ì´í„° ì£¼ê°„ ì‹ë³„
            low_data_weeks = weekly_counts[weekly_counts < self.weekly_merge_threshold].index
            
            weekly_groups = {}
            merge_buffer = []
            
            for period, group_df in df.groupby('year_week'):
                period_str = str(period)
                
                if period in low_data_weeks:
                    # ì €ë°ì´í„° ì£¼ê°„ì€ ë²„í¼ì— ì¶”ê°€ (ì ˆëŒ€ ìµœì†Œê°’ í™•ì¸)
                    if len(group_df) >= self.absolute_min_threshold:
                        merge_buffer.append((period_str, group_df.drop('year_week', axis=1).copy()))
                    else:
                        self.logger.info(f"âš ï¸ ì£¼ê°„ {period_str}: ë°ì´í„° ë„ˆë¬´ ë¶€ì¡±({len(group_df)}ê°œ), ì™„ì „ ì œì™¸")
                else:
                    # ì •ìƒ ë°ì´í„° ì£¼ê°„
                    if merge_buffer:
                        # ì´ì „ ì €ë°ì´í„° ì£¼ê°„ë“¤ê³¼ ë³‘í•©
                        merged_df = pd.concat([item[1] for item in merge_buffer] + [group_df.drop('year_week', axis=1).copy()])
                        
                        # ë³‘í•© í›„ì—ë„ ìµœì†Œ ì„ê³„ê°’ í™•ì¸
                        if len(merged_df) >= self.absolute_min_threshold:
                            merged_period = f"{merge_buffer[0][0]}_to_{period_str}"
                            weekly_groups[merged_period] = merged_df
                            self.logger.info(f"ğŸ“… {merged_period}: ì €ë°ì´í„° ì£¼ê°„ ë³‘í•© ({len(merged_df)}ê°œ ëŒ“ê¸€)")
                        else:
                            self.logger.info(f"âš ï¸ ë³‘í•© ì£¼ê°„ {merge_buffer[0][0]}_to_{period_str}: ë³‘í•© í›„ì—ë„ ë°ì´í„° ë¶€ì¡±({len(merged_df)}ê°œ), ì œì™¸")
                        
                        merge_buffer = []
                    else:
                        # ë‹¨ë… ì •ìƒ ì£¼ê°„ë„ ìµœì†Œ ì„ê³„ê°’ í™•ì¸
                        if len(group_df) >= self.absolute_min_threshold:
                            weekly_groups[period_str] = group_df.drop('year_week', axis=1).copy()
                        else:
                            self.logger.info(f"âš ï¸ ì£¼ê°„ {period_str}: ë°ì´í„° ë¶€ì¡±({len(group_df)}ê°œ), ì œì™¸")
            
            # ë§ˆì§€ë§‰ì— ë‚¨ì€ ì €ë°ì´í„° ì£¼ê°„ë“¤ ì²˜ë¦¬
            if merge_buffer:
                if len(weekly_groups) > 0:
                    # ë§ˆì§€ë§‰ ì •ìƒ ì£¼ê°„ê³¼ ë³‘í•©
                    last_key = list(weekly_groups.keys())[-1]
                    last_df = weekly_groups[last_key]
                    merged_df = pd.concat([last_df] + [item[1] for item in merge_buffer])
                    
                    # ë³‘í•© í›„ ìµœì†Œ ì„ê³„ê°’ í™•ì¸
                    if len(merged_df) >= self.absolute_min_threshold:
                        weekly_groups[f"{last_key}_extended"] = merged_df
                        del weekly_groups[last_key]
                        self.logger.info(f"ğŸ“… {last_key}_extended: ë§ˆì§€ë§‰ ì €ë°ì´í„° ì£¼ê°„ ë³‘í•© ({len(merged_df)}ê°œ ëŒ“ê¸€)")
                    else:
                        self.logger.info(f"âš ï¸ ë§ˆì§€ë§‰ ë³‘í•© ì£¼ê°„: ë°ì´í„° ë¶€ì¡±({len(merged_df)}ê°œ), ê¸°ì¡´ ìœ ì§€")
                else:
                    # ëª¨ë“  ì£¼ê°„ì´ ì €ë°ì´í„°ì¸ ê²½ìš° ì „ì²´ ë³‘í•©
                    merged_df = pd.concat([item[1] for item in merge_buffer])
                    if len(merged_df) >= self.absolute_min_threshold:
                        weekly_groups['all_weeks_merged'] = merged_df
                        self.logger.info(f"ğŸ“… all_weeks_merged: ì „ì²´ ì €ë°ì´í„° ì£¼ê°„ ë³‘í•© ({len(merged_df)}ê°œ ëŒ“ê¸€)")
                    else:
                        self.logger.info(f"âš ï¸ ì „ì²´ ì£¼ê°„ ë³‘í•©: ë°ì´í„° ë¶€ì¡±({len(merged_df)}ê°œ), ì£¼ê°„ ë¶„ì„ ë¶ˆê°€")
            
            self.logger.info(f"ğŸ“… ì£¼ê°„ ê·¸ë£¹ ìƒì„± ì™„ë£Œ: {len(weekly_groups)}ê°œ ì£¼ê°„ (í•„í„°ë§ ê°•í™”)")
            return weekly_groups
            
        except Exception as e:
            self.logger.error(f"âŒ ì£¼ê°„ ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _create_adaptive_hybrid_groups(self, df: pd.DataFrame, date_column: str) -> Dict:
        """
        ì ì‘í˜• í˜¼í•© ê·¸ë£¹ ìƒì„± (ë°ì´í„° ë°€ë„ì— ë”°ë¼ ì›”ë³„/ì£¼ê°„ í˜¼í•©)
        ê³ ë°€ë„ êµ¬ê°„ì€ ì£¼ê°„ìœ¼ë¡œ ì„¸ë¶„í™”, ì €ë°€ë„ êµ¬ê°„ì€ ì›”ë³„ ìœ ì§€
        """
        try:
            self.logger.info("ğŸ”„ ì ì‘í˜• í˜¼í•© ê·¸ë£¹ ìƒì„± ì‹œì‘")
            
            # ë¨¼ì € ì›”ë³„ ë¶„í¬ ë¶„ì„
            monthly_groups = self._create_monthly_groups(df, date_column)
            
            adaptive_groups = {}
            
            # ì „ì²´ ëŒ“ê¸€ ìˆ˜ ê³„ì‚°
            total_comments = sum(len(month_df) for month_df in monthly_groups.values())
            
            # ë¹„ìœ¨ ê¸°ë°˜ ì„ê³„ê°’ ì„¤ì •
            high_density_ratio = 0.25  # ì „ì²´ì˜ 25% ì´ìƒì´ë©´ ì£¼ê°„ ì„¸ë¶„í™”
            medium_density_ratio = 0.05  # ì „ì²´ì˜ 5% ì´ìƒì´ë©´ ì›”ë³„ ìœ ì§€
            min_ratio = 0.01  # ì „ì²´ì˜ 1% ì´ìƒì´ë©´ ìµœì†Œ ìœ ì§€
            
            high_density_threshold = max(total_comments * high_density_ratio, self.min_comments_per_period)
            medium_density_threshold = max(total_comments * medium_density_ratio, self.absolute_min_threshold)
            min_threshold = max(total_comments * min_ratio, self.absolute_min_threshold)
            
            self.logger.info(f"ğŸ“Š ë¹„ìœ¨ ê¸°ë°˜ ì„ê³„ê°’ ì„¤ì • (ì´ {total_comments:,}ê°œ ëŒ“ê¸€)")
            self.logger.info(f"  ğŸ”¥ ê³ ë°€ë„ ì„ê³„ê°’: {high_density_threshold:.0f}ê°œ ({high_density_ratio:.1%})")
            self.logger.info(f"  ğŸ“Š ì¤‘ë°€ë„ ì„ê³„ê°’: {medium_density_threshold:.0f}ê°œ ({medium_density_ratio:.1%})")
            self.logger.info(f"  ğŸ“‰ ìµœì†Œ ì„ê³„ê°’: {min_threshold:.0f}ê°œ ({min_ratio:.1%})")
            
            for month_key, month_df in monthly_groups.items():
                comment_count = len(month_df)
                comment_ratio = comment_count / total_comments
                
                if comment_count >= high_density_threshold:
                    # ğŸ”§ ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ ì œì•½ í™•ì¸
                    if self.min_time_unit == 'monthly':
                        # ì›”ë³„ë§Œ í—ˆìš© - ì„¸ë¶„í™” ì•ˆí•¨
                        self.logger.info(f"ğŸ”§ {month_key}: {comment_count:,}ê°œ ëŒ“ê¸€ ({comment_ratio:.1%}) â†’ ì›”ë³„ ìœ ì§€ (ìµœì†Œ ë‹¨ìœ„ ì œì•½)")
                        adaptive_groups[month_key] = month_df.copy()
                    elif self.min_time_unit in ['weekly', 'daily']:
                        # ì£¼ê°„ ì„¸ë¶„í™” í—ˆìš©
                        self.logger.info(f"ğŸ”¥ {month_key}: {comment_count:,}ê°œ ëŒ“ê¸€ ({comment_ratio:.1%}) â†’ ì£¼ê°„ ì„¸ë¶„í™”")
                        
                        # ì˜¬ë°”ë¥¸ ì£¼ê°„ ê·¸ë£¹í™” ì‚¬ìš©
                        month_df_copy = month_df.copy()
                        month_df_copy['year_week'] = month_df_copy[date_column].dt.to_period('W')
                        
                        week_groups = {}
                        for week_period, week_df in month_df_copy.groupby('year_week'):
                            if len(week_df) >= self.absolute_min_threshold:
                                # ì£¼ê°„ í‚¤ ìƒì„± (ì‹œì‘ì¼~ì¢…ë£Œì¼ í˜•ì‹)
                                week_start = week_df[date_column].min().strftime('%Y-%m-%d')
                                week_end = week_df[date_column].max().strftime('%Y-%m-%d')
                                week_key = f"{week_start} ~ {week_end}"
                                
                                week_groups[week_key] = week_df.drop('year_week', axis=1).copy()
                                week_ratio = len(week_df) / total_comments
                                self.logger.info(f"  ğŸ“… {week_key}: {len(week_df):,}ê°œ ëŒ“ê¸€ ({week_ratio:.1%})")
                        
                        # ì£¼ê°„ ê·¸ë£¹ì´ ì—¬ëŸ¬ ê°œ ìƒì„±ë˜ì—ˆìœ¼ë©´ ì¶”ê°€, ì•„ë‹ˆë©´ ì›”ë³„ ìœ ì§€
                        if len(week_groups) > 1:
                            adaptive_groups.update(week_groups)
                        else:
                            self.logger.info(f"  ğŸ“… ì£¼ê°„ ì„¸ë¶„í™” íš¨ê³¼ ì—†ìŒ, ì›”ë³„ ìœ ì§€: {month_key}")
                            adaptive_groups[month_key] = month_df.copy()
                    else:
                        # ì•Œ ìˆ˜ ì—†ëŠ” ì„¤ì • - ì›”ë³„ ìœ ì§€
                        self.logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ìµœì†Œ ì‹œê°„ ë‹¨ìœ„: {self.min_time_unit}, ì›”ë³„ ìœ ì§€")
                        adaptive_groups[month_key] = month_df.copy()
                
                elif comment_count >= medium_density_threshold:
                    # ì¤‘ë°€ë„ êµ¬ê°„: ì›”ë³„ ìœ ì§€
                    self.logger.info(f"ğŸ“Š {month_key}: {comment_count:,}ê°œ ëŒ“ê¸€ ({comment_ratio:.1%}) â†’ ì›”ë³„ ìœ ì§€")
                    adaptive_groups[month_key] = month_df.copy()
                
                elif comment_count >= min_threshold:
                    # ì €ë°€ë„ êµ¬ê°„: ì›”ë³„ ìœ ì§€ (ìµœì†Œ ê¸°ì¤€ ì¶©ì¡±)
                    self.logger.info(f"ğŸ“‰ {month_key}: {comment_count:,}ê°œ ëŒ“ê¸€ ({comment_ratio:.1%}) â†’ ì›”ë³„ ìœ ì§€ (ì €ë°€ë„)")
                    adaptive_groups[month_key] = month_df.copy()
                
                else:
                    # ë§¤ìš° ì €ë°€ë„: ì œì™¸
                    self.logger.warning(f"âš ï¸ {month_key}: {comment_count:,}ê°œ ëŒ“ê¸€ ({comment_ratio:.1%}) â†’ ì œì™¸ (ìµœì†Œ ê¸°ì¤€ ë¯¸ë‹¬)")
            
            self.logger.info(f"âœ… ì ì‘í˜• í˜¼í•© ê·¸ë£¹ ìƒì„± ì™„ë£Œ: {len(adaptive_groups)}ê°œ ê·¸ë£¹")
            
            # ê·¸ë£¹ ì •ë³´ ìš”ì•½
            total_comments = sum(len(group_df) for group_df in adaptive_groups.values())
            weekly_groups = [k for k in adaptive_groups.keys() if '_W' in k]
            monthly_groups_kept = [k for k in adaptive_groups.keys() if '_W' not in k]
            
            self.logger.info(f"  ğŸ“Š ì´ ëŒ“ê¸€ ìˆ˜: {total_comments}ê°œ")
            self.logger.info(f"  ğŸ—“ï¸ ì£¼ê°„ ì„¸ë¶„í™” ê·¸ë£¹: {len(weekly_groups)}ê°œ")
            self.logger.info(f"  ğŸ“… ì›”ë³„ ìœ ì§€ ê·¸ë£¹: {len(monthly_groups_kept)}ê°œ")
            
            return adaptive_groups
            
        except Exception as e:
            self.logger.error(f"âŒ ì ì‘í˜• í˜¼í•© ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì›”ë³„ ê·¸ë£¹ìœ¼ë¡œ í´ë°±
            return self._create_monthly_groups(df, date_column)
    
    def _create_hybrid_groups(self, df: pd.DataFrame, date_column: str) -> Dict:
        """í˜¼í•© ê·¸ë£¹ ìƒì„± (ì›”ë³„ + ì£¼ê°„) - ì£¼ê°„ ìš°ì„  ì •ì±…"""
        try:
            # ë¨¼ì € ì›”ë³„ ë¶„í¬ í™•ì¸
            df['year_month'] = df[date_column].dt.to_period('M')
            monthly_counts = df.groupby('year_month').size()
            
            # ë°ì´í„°ê°€ ì¶©ë¶„í•œ ì›”ê³¼ ë¶€ì¡±í•œ ì›” êµ¬ë¶„
            sufficient_months = monthly_counts[monthly_counts >= self.min_comments_per_period].index
            insufficient_months = monthly_counts[monthly_counts < self.min_comments_per_period].index
            
            hybrid_groups = {}
            
            # ë°ì´í„°ê°€ ì¶©ë¶„í•œ ì›”ì€ ì£¼ê°„ ë¶„ì„ (ì›”ê°„ êµ¬ê°„ ì œê±°)
            for month in sufficient_months:
                month_df = df[df['year_month'] == month].copy()
                month_df['year_week'] = month_df[date_column].dt.to_period('W')
                
                week_groups = {}
                for week, week_df in month_df.groupby('year_week'):
                    if len(week_df) >= self.absolute_min_threshold:  # ì£¼ê°„ë„ ìµœì†Œ ì„ê³„ê°’ í™•ì¸
                        week_str = str(week)
                        week_groups[week_str] = week_df.drop(['year_month', 'year_week'], axis=1).copy()
                
                # ì£¼ê°„ ê·¸ë£¹ì´ ìˆìœ¼ë©´ ì¶”ê°€ (ì›”ê°„ êµ¬ê°„ì€ ì œì™¸)
                if week_groups:
                    hybrid_groups.update(week_groups)
                    self.logger.info(f"ğŸ“… {month}: ì£¼ê°„ ë¶„ì„ ì ìš© ({len(week_groups)}ê°œ ì£¼ê°„)")
            
            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ì›”ë“¤ì€ ë³‘í•©í•˜ì—¬ ì›”ë³„ ë¶„ì„ (ìµœì†Œ ì„ê³„ê°’ í™•ì¸)
            if len(insufficient_months) > 0:
                insufficient_df = df[df['year_month'].isin(insufficient_months)].copy()
                
                # ì—°ì†ëœ ë¶€ì¡±í•œ ì›”ë“¤ì„ ê·¸ë£¹í™”
                month_groups = []
                current_group = []
                
                for month in sorted(insufficient_months):
                    if not current_group or (month - current_group[-1]).n == 1:
                        current_group.append(month)
                    else:
                        month_groups.append(current_group)
                        current_group = [month]
                
                if current_group:
                    month_groups.append(current_group)
                
                # ê° ê·¸ë£¹ì„ í•˜ë‚˜ì˜ ê¸°ê°„ìœ¼ë¡œ ì²˜ë¦¬ (ìµœì†Œ ì„ê³„ê°’ í™•ì¸)
                for i, month_group in enumerate(month_groups):
                    group_df = insufficient_df[insufficient_df['year_month'].isin(month_group)].copy()
                    
                    # ìµœì†Œ ì„ê³„ê°’ í™•ì¸
                    if len(group_df) >= self.absolute_min_threshold:
                        if len(month_group) == 1:
                            group_key = str(month_group[0])
                        else:
                            group_key = f"{month_group[0]}_to_{month_group[-1]}"
                        
                        hybrid_groups[group_key] = group_df.drop('year_month', axis=1).copy()
                        self.logger.info(f"ğŸ“… {group_key}: ì›”ê°„ ë¶„ì„ ì ìš© ({len(group_df)}ê°œ ëŒ“ê¸€)")
                    else:
                        self.logger.info(f"âš ï¸ ì›”ê°„ ê·¸ë£¹ {month_group}: ë°ì´í„° ë¶€ì¡±({len(group_df)}ê°œ), ì œì™¸")
            
            self.logger.info(f"ğŸ“… í˜¼í•© ê·¸ë£¹ ìƒì„± ì™„ë£Œ: {len(hybrid_groups)}ê°œ ê¸°ê°„ (ì£¼ê°„ ìš°ì„  ì •ì±…)")
            return hybrid_groups
            
        except Exception as e:
            self.logger.error(f"âŒ í˜¼í•© ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def visualize_time_distribution(self, distribution_result: Dict, df: pd.DataFrame = None, 
                                  date_column: str = 'date', save_path: str = None) -> str:
        """
        ì‹œê°„ ë¶„í¬ ì‹œê°í™” (ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ì— ë”°ë¥¸ ê°•ì œ í‘œê¸°)
        Args:
            distribution_result: analyze_time_distribution ê²°ê³¼
            df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„ (ì ˆëŒ€ ì‹œê°„ ê³„ì‚°ìš©)
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
            save_path: ì €ì¥ ê²½ë¡œ
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            if not distribution_result:
                self.logger.error("âŒ ë¶„í¬ ê²°ê³¼ê°€ ì—†ì–´ ì‹œê°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # í•œê¸€ í°íŠ¸ ì„¤ì • ê°•í™”
            self._setup_korean_font_for_plot()
            
            # 1x2 ë ˆì´ì•„ì›ƒìœ¼ë¡œ ë³€ê²½ (ì ˆëŒ€ ì‹œê°„ ê¸°ì¤€ë§Œ í‘œì‹œ)
            fig, axes = plt.subplots(1, 2, figsize=(16, 6))
            fig.suptitle(f'ì‹œê°„ë³„ ëŒ“ê¸€ ë¶„í¬ ë¶„ì„ (ìµœì†Œ ë‹¨ìœ„: {self.min_time_unit})', fontsize=16, fontweight='bold')
            
            # ğŸ”§ ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ì— ë”°ë¥¸ ê°•ì œ í‘œê¸°
            if df is not None and date_column in df.columns:
                df_copy = df.copy()
                df_copy[date_column] = pd.to_datetime(df_copy[date_column])
                
                # 1. ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ì— ë”°ë¥¸ ì²« ë²ˆì§¸ í”Œë¡¯
                if self.min_time_unit == 'monthly':
                    # ì›”ë³„ í‘œê¸° ê°•ì œ
                    df_copy['time_group'] = df_copy[date_column].dt.to_period('M')
                    time_counts = df_copy.groupby('time_group').size().sort_index()
                    time_labels = [pd.to_datetime(str(period)).strftime('%Y-%m') for period in time_counts.index]
                    plot_title = 'ì›”ë³„ ëŒ“ê¸€ ë¶„í¬'
                    xlabel = 'ë…„-ì›”'
                    
                elif self.min_time_unit == 'weekly':
                    # ì£¼ë³„ í‘œê¸° ê°•ì œ
                    df_copy['time_group'] = df_copy[date_column].dt.to_period('W')
                    time_counts = df_copy.groupby('time_group').size().sort_index()
                    # ì£¼ë³„ ë¼ë²¨ì„ "YYYY-WXX" í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                    time_labels = []
                    for period in time_counts.index:
                        week_start = pd.to_datetime(str(period).split('/')[0])
                        week_num = week_start.isocalendar()[1]
                        time_labels.append(f"{week_start.year}-W{week_num:02d}")
                    plot_title = 'ì£¼ë³„ ëŒ“ê¸€ ë¶„í¬'
                    xlabel = 'ë…„-ì£¼ì°¨'
                    
                elif self.min_time_unit == 'daily':
                    # ì¼ë³„ í‘œê¸° ê°•ì œ
                    df_copy['time_group'] = df_copy[date_column].dt.date
                    time_counts = df_copy.groupby('time_group').size().sort_index()
                    time_labels = [date.strftime('%m-%d') for date in time_counts.index]
                    plot_title = 'ì¼ë³„ ëŒ“ê¸€ ë¶„í¬'
                    xlabel = 'ì›”-ì¼'
                else:
                    # ê¸°ë³¸ê°’: ì›”ë³„
                    df_copy['time_group'] = df_copy[date_column].dt.to_period('M')
                    time_counts = df_copy.groupby('time_group').size().sort_index()
                    time_labels = [pd.to_datetime(str(period)).strftime('%Y-%m') for period in time_counts.index]
                    plot_title = 'ì›”ë³„ ëŒ“ê¸€ ë¶„í¬ (ê¸°ë³¸ê°’)'
                    xlabel = 'ë…„-ì›”'
                
                # ì²« ë²ˆì§¸ í”Œë¡¯: ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ ê¸°ì¤€
                bars1 = axes[0].bar(range(len(time_counts)), time_counts.values, 
                                      color='skyblue', alpha=0.7, edgecolor='navy', linewidth=1)
                axes[0].set_title(f'{plot_title} (ê°•ì œ í‘œê¸°)', fontsize=14, fontweight='bold')
                axes[0].set_xlabel(xlabel, fontsize=12)
                axes[0].set_ylabel('ëŒ“ê¸€ ìˆ˜', fontsize=12)
                
                # xì¶• ë¼ë²¨ ì„¤ì • (ë„ˆë¬´ ë§ìœ¼ë©´ ìƒ˜í”Œë§)
                if len(time_labels) > 15:
                    # 15ê°œ ì´ìƒì´ë©´ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
                    sample_indices = np.linspace(0, len(time_labels)-1, 15, dtype=int)
                    axes[0].set_xticks(sample_indices)
                    axes[0].set_xticklabels([time_labels[i] for i in sample_indices], rotation=45, ha='right')
                else:
                    axes[0].set_xticks(range(len(time_labels)))
                    axes[0].set_xticklabels(time_labels, rotation=45, ha='right')
                
                axes[0].grid(True, alpha=0.3)
                
                # ê°’ í‘œì‹œ
                for i, (bar, count) in enumerate(zip(bars1, time_counts.values)):
                    if i < len(bars1):  # ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸
                        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(time_counts.values) * 0.01,
                                       f'{count:,}', ha='center', va='bottom', fontsize=9, fontweight='bold')
                
                # 2. ì‹¤ì œ ë°ì´í„° ë¶„í¬ (ì°¸ê³ ìš©)
                # ì‹¤ì œ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ë¶„í¬ë˜ì–´ ìˆëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” í”Œë¡¯
                df_copy['actual_date'] = df_copy[date_column].dt.date
                daily_counts = df_copy.groupby('actual_date').size().sort_index()
                
                # ì¼ë³„ ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ë³„ë¡œ ì§‘ê³„
                if len(daily_counts) > 30:
                    df_copy['week_group'] = df_copy[date_column].dt.to_period('W')
                    weekly_counts = df_copy.groupby('week_group').size().sort_index()
                    
                    # ì£¼ë³„ ë¼ë²¨ ìƒì„±
                    week_dates = [pd.to_datetime(str(period).split('/')[0]) for period in weekly_counts.index]
                    week_labels = [date.strftime('%m/%d') for date in week_dates]
                    
                    axes[1].plot(range(len(weekly_counts)), weekly_counts.values, 
                                   marker='o', markersize=6, linewidth=2, color='orange', alpha=0.8)
                    axes[1].set_title('ì‹¤ì œ ë°ì´í„° ë¶„í¬ (ì£¼ë³„ ì§‘ê³„)', fontsize=14, fontweight='bold')
                    axes[1].set_xlabel('ì£¼ ì‹œì‘ì¼ (ì›”/ì¼)', fontsize=12)
                    
                    # xì¶• ë¼ë²¨ ì„¤ì •
                    if len(week_labels) > 15:
                        sample_indices = np.linspace(0, len(week_labels)-1, 15, dtype=int)
                        axes[1].set_xticks(sample_indices)
                        axes[1].set_xticklabels([week_labels[i] for i in sample_indices], rotation=45, ha='right')
                    else:
                        axes[1].set_xticks(range(len(week_labels)))
                        axes[1].set_xticklabels(week_labels, rotation=45, ha='right')
                    
                    # í”¼í¬ í¬ì¸íŠ¸ í‘œì‹œ
                    if len(weekly_counts) > 0:
                        max_idx = weekly_counts.values.argmax()
                        max_value = weekly_counts.values[max_idx]
                        axes[1].annotate(f'ìµœëŒ€: {max_value:,}ê°œ', 
                                           xy=(max_idx, max_value), 
                                           xytext=(max_idx, max_value + max_value * 0.1),
                                           arrowprops=dict(arrowstyle='->', color='red', lw=2),
                                           fontsize=10, ha='center', color='red', fontweight='bold')
                else:
                    # ì¼ë³„ ë°ì´í„°ê°€ ì ìœ¼ë©´ ê·¸ëŒ€ë¡œ í‘œì‹œ
                    daily_labels = [date.strftime('%m-%d') for date in daily_counts.index]
                    
                    axes[1].plot(range(len(daily_counts)), daily_counts.values, 
                                   marker='o', markersize=6, linewidth=2, color='green', alpha=0.8)
                    axes[1].set_title('ì‹¤ì œ ë°ì´í„° ë¶„í¬ (ì¼ë³„)', fontsize=14, fontweight='bold')
                    axes[1].set_xlabel('ì›”-ì¼', fontsize=12)
                    
                    # xì¶• ë¼ë²¨ ì„¤ì •
                    if len(daily_labels) > 15:
                        sample_indices = np.linspace(0, len(daily_labels)-1, 15, dtype=int)
                        axes[1].set_xticks(sample_indices)
                        axes[1].set_xticklabels([daily_labels[i] for i in sample_indices], rotation=45, ha='right')
                    else:
                        axes[1].set_xticks(range(len(daily_labels)))
                        axes[1].set_xticklabels(daily_labels, rotation=45, ha='right')
                    
                    # í”¼í¬ í¬ì¸íŠ¸ í‘œì‹œ
                    if len(daily_counts) > 0:
                        max_idx = daily_counts.values.argmax()
                        max_value = daily_counts.values[max_idx]
                        axes[1].annotate(f'ìµœëŒ€: {max_value:,}ê°œ', 
                                           xy=(max_idx, max_value), 
                                           xytext=(max_idx, max_value + max_value * 0.1),
                                           arrowprops=dict(arrowstyle='->', color='red', lw=2),
                                           fontsize=10, ha='center', color='red', fontweight='bold')
                
                axes[1].set_ylabel('ëŒ“ê¸€ ìˆ˜', fontsize=12)
                axes[1].grid(True, alpha=0.3)
            
            else:
                # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë©”ì‹œì§€ í‘œì‹œ
                for ax in axes:
                    ax.text(0.5, 0.5, 'ë°ì´í„° ì—†ìŒ', ha='center', va='center', 
                           transform=ax.transAxes, fontsize=14, color='gray')
                    ax.set_title('ë°ì´í„° ì—†ìŒ', fontsize=14)
            
            # Time Interval ì •ë³´ë¥¼ ë³„ë„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
            self._save_time_interval_info(distribution_result, df, date_column, save_path)
            
            plt.tight_layout()
            
            # ì €ì¥
            if not save_path:
                save_path = os.path.join(self.config.OUTPUT_STRUCTURE['visualizations'], 'time_distribution_analysis.png')
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()
            
            self.logger.info(f"ğŸ“Š ì‹œê°„ ë¶„í¬ ì‹œê°í™” ì €ì¥: {save_path}")
            self.logger.info(f"ğŸ”§ ìµœì†Œ ì‹œê°„ ë‹¨ìœ„ '{self.min_time_unit}'ì— ë”°ë¥¸ ê°•ì œ í‘œê¸° ì ìš©")
            return save_path
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°„ ë¶„í¬ ì‹œê°í™” ì‹¤íŒ¨: {str(e)}")
            import traceback
            self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None
    
    def _save_time_interval_info(self, distribution_result: Dict, df: pd.DataFrame = None, 
                                date_column: str = 'date', save_path: str = None):
        """
        Time Interval ì •ë³´ë¥¼ ë³„ë„ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        Args:
            distribution_result: analyze_time_distribution ê²°ê³¼
            df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
            date_column: ë‚ ì§œ ì»¬ëŸ¼ëª…
            save_path: ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ (í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ìƒì„±ìš©)
        """
        try:
            # í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ ìƒì„±
            if save_path:
                text_path = save_path.replace('.png', '_time_interval_info.txt')
            else:
                text_path = os.path.join(self.config.OUTPUT_STRUCTURE['visualizations'], 'time_distribution_interval_info.txt')
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(text_path), exist_ok=True)
            
            # Time Interval ì •ë³´ ìƒì„±
            interval_info_lines = []
            interval_info_lines.append("=" * 80)
            interval_info_lines.append("ì‹œê°„ ë¶„í¬ ë¶„ì„ - Time Interval ì •ë³´")
            interval_info_lines.append("=" * 80)
            interval_info_lines.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            interval_info_lines.append("")
            
            # 1. ê¸°ë³¸ ê¶Œì¥ì‚¬í•­ ì •ë³´
            optimal_unit = distribution_result.get('optimal_time_unit', 'monthly')
            recommendation = distribution_result.get('recommendation', {})
            
            interval_info_lines.append("ğŸ“Š ê¶Œì¥ ë¶„ì„ ë‹¨ìœ„ ì •ë³´")
            interval_info_lines.append("-" * 40)
            interval_info_lines.append(f"ê¶Œì¥ ë¶„ì„ ë‹¨ìœ„: {optimal_unit}")
            
            if recommendation:
                interval_info_lines.append(f"ë¶„ì„ ê¸°ê°„ ìˆ˜: {recommendation.get('total_periods', 'N/A')}ê°œ")
                avg_comments = recommendation.get('avg_comments_per_period', 'N/A')
                if isinstance(avg_comments, (int, float)):
                    interval_info_lines.append(f"í‰ê·  ëŒ“ê¸€/ê¸°ê°„: {avg_comments:,.0f}ê°œ")
                else:
                    interval_info_lines.append(f"í‰ê·  ëŒ“ê¸€/ê¸°ê°„: {avg_comments}ê°œ")
                interval_info_lines.append(f"ë°ì´í„° í’ˆì§ˆ: {recommendation.get('data_quality', 'N/A')}")
                
                # ê¶Œì¥ì‚¬í•­ ì´ìœ 
                if 'reasons' in recommendation:
                    interval_info_lines.append("\nê¶Œì¥ ì´ìœ :")
                    for reason in recommendation['reasons']:
                        interval_info_lines.append(f"  â€¢ {reason}")
                
                # ê²½ê³ ì‚¬í•­
                if 'warnings' in recommendation:
                    interval_info_lines.append("\nì£¼ì˜ì‚¬í•­:")
                    for warning in recommendation['warnings']:
                        interval_info_lines.append(f"  âš ï¸ {warning}")
                
                # ì œì•ˆì‚¬í•­
                if 'suggestions' in recommendation:
                    interval_info_lines.append("\nì œì•ˆì‚¬í•­:")
                    for suggestion in recommendation['suggestions']:
                        interval_info_lines.append(f"  ğŸ’¡ {suggestion}")
            
            interval_info_lines.append("")
            
            # 2. ìƒì„¸ Time Interval í†µê³„ (ì›ë³¸ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            if df is not None and date_column in df.columns:
                interval_info_lines.append("ğŸ“… ìƒì„¸ Time Interval í†µê³„")
                interval_info_lines.append("-" * 40)
                
                # ìµœì  ë‹¨ìœ„ì— ë”°ë¥¸ ì‹¤ì œ ê·¸ë£¹ ìƒì„±
                df_detail = df.copy()
                df_detail[date_column] = pd.to_datetime(df_detail[date_column])
                
                if optimal_unit in ['monthly', 'monthly_forced']:
                    df_detail['time_group'] = df_detail[date_column].dt.to_period('M')
                elif optimal_unit == 'weekly':
                    df_detail['time_group'] = df_detail[date_column].dt.to_period('W')
                else:  # hybrid
                    df_detail['time_group'] = df_detail[date_column].dt.to_period('M')
                
                # ì‹¤ì œ time intervalë³„ í†µê³„
                if 'comment_text' in df_detail.columns:
                    time_interval_stats = df_detail.groupby('time_group').agg({
                        'comment_text': 'count',
                        date_column: ['min', 'max']
                    }).round(0)
                    time_interval_stats.columns = ['comment_count', 'start_date', 'end_date']
                else:
                    # comment_text ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©
                    first_col = df_detail.columns[0]
                    time_interval_stats = df_detail.groupby('time_group').agg({
                        first_col: 'count',
                        date_column: ['min', 'max']
                    }).round(0)
                    time_interval_stats.columns = ['comment_count', 'start_date', 'end_date']
                
                # ì „ì²´ í†µê³„ ìš”ì•½
                interval_info_lines.append(f"ì´ ë¶„ì„ ê¸°ê°„ ìˆ˜: {len(time_interval_stats)}ê°œ")
                interval_info_lines.append(f"í‰ê·  ëŒ“ê¸€/ê¸°ê°„: {time_interval_stats['comment_count'].mean():.0f}ê°œ")
                interval_info_lines.append(f"ì¤‘ì•™ê°’ ëŒ“ê¸€/ê¸°ê°„: {time_interval_stats['comment_count'].median():.0f}ê°œ")
                interval_info_lines.append(f"ìµœëŒ€ ëŒ“ê¸€/ê¸°ê°„: {time_interval_stats['comment_count'].max():,}ê°œ")
                interval_info_lines.append(f"ìµœì†Œ ëŒ“ê¸€/ê¸°ê°„: {time_interval_stats['comment_count'].min():,}ê°œ")
                
                # ë°ì´í„° í’ˆì§ˆ í‰ê°€
                cv = time_interval_stats['comment_count'].std() / time_interval_stats['comment_count'].mean()
                if cv < 0.5:
                    quality = "ë§¤ìš° ì¢‹ìŒ"
                elif cv < 1.0:
                    quality = "ì¢‹ìŒ"
                elif cv < 1.5:
                    quality = "ë³´í†µ"
                else:
                    quality = "ë¶ˆê· ë“±"
                
                interval_info_lines.append(f"ë°ì´í„° í’ˆì§ˆ í‰ê°€: {quality}")
                interval_info_lines.append(f"ë³€ë™ê³„ìˆ˜(CV): {cv:.2f}")
                
                # ì‹œê°„ ë²”ìœ„ ì •ë³´
                total_start = pd.to_datetime(time_interval_stats['start_date'].min()).strftime('%Y-%m-%d')
                total_end = pd.to_datetime(time_interval_stats['end_date'].max()).strftime('%Y-%m-%d')
                total_days = (pd.to_datetime(time_interval_stats['end_date'].max()) - 
                             pd.to_datetime(time_interval_stats['start_date'].min())).days + 1
                
                interval_info_lines.append(f"\nì „ì²´ ë¶„ì„ ê¸°ê°„:")
                interval_info_lines.append(f"  ì‹œì‘: {total_start}")
                interval_info_lines.append(f"  ì¢…ë£Œ: {total_end}")
                interval_info_lines.append(f"  ì´ ì¼ìˆ˜: {total_days:,}ì¼")
                
                # ëª¨ë“  Time Interval ìƒì„¸ ì •ë³´
                interval_info_lines.append(f"\nğŸ“‹ ì „ì²´ Time Interval ìƒì„¸ ì •ë³´ ({len(time_interval_stats)}ê°œ)")
                interval_info_lines.append("-" * 60)
                interval_info_lines.append(f"{'ìˆœìœ„':<4} {'ê¸°ê°„':<20} {'ì‹œì‘ì¼':<12} {'ì¢…ë£Œì¼':<12} {'ëŒ“ê¸€ìˆ˜':<10}")
                interval_info_lines.append("-" * 60)
                
                # ëŒ“ê¸€ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                sorted_intervals = time_interval_stats.sort_values('comment_count', ascending=False)
                
                for i, (period, row) in enumerate(sorted_intervals.iterrows(), 1):
                    start_date = pd.to_datetime(row['start_date']).strftime('%Y-%m-%d')
                    end_date = pd.to_datetime(row['end_date']).strftime('%Y-%m-%d')
                    comment_count = int(row['comment_count'])
                    
                    period_str = str(period)
                    if len(period_str) > 18:
                        period_str = period_str[:15] + "..."
                    
                    interval_info_lines.append(f"{i:<4} {period_str:<20} {start_date:<12} {end_date:<12} {comment_count:,}")
                
            else:
                interval_info_lines.append("ğŸ“… ìƒì„¸ Time Interval í†µê³„")
                interval_info_lines.append("-" * 40)
                interval_info_lines.append("âš ï¸ ìƒì„¸ ì •ë³´ë¥¼ ìœ„í•´ì„œëŠ” ì›ë³¸ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
            interval_info_lines.append("")
            interval_info_lines.append("=" * 80)
            interval_info_lines.append("ë¶„ì„ ì™„ë£Œ")
            interval_info_lines.append("=" * 80)
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
            with open(text_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(interval_info_lines))
            
            self.logger.info(f"ğŸ“„ Time Interval ì •ë³´ ì €ì¥: {text_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ Time Interval ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            import traceback
            self.logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}") 