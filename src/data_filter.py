"""
Data Filter Module
ë°ì´í„° í•„í„°ë§ ëª¨ë“ˆ - ëŒ“ê¸€ í’ˆì§ˆ ë° ê´€ë ¨ì„± í•„í„°ë§
"""

import pandas as pd
import numpy as np
import logging
import re
from typing import Dict, List, Tuple, Optional
from collections import Counter
import difflib
from tqdm import tqdm

class DataFilter:
    """ë°ì´í„° í•„í„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, config):
        """
        ì´ˆê¸°í™”
        Args:
            config: AnalysisConfig ê°ì²´
        """
        self.config = config
        self.logger = self._setup_logger()
        self.filtering_config = config.COMMENT_FILTERING
        
        # í•„í„°ë§ í†µê³„
        self.filter_stats = {
            'original_count': 0,
            'upvote_filtered': 0,
            'keyword_filtered': 0,
            'quality_filtered': 0,
            'duplicate_filtered': 0,
            'user_filtered': 0,
            'final_count': 0
        }
    
    def _setup_logger(self):
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger(__name__)
        logger.setLevel(getattr(logging, self.config.LOGGING['level']))
        
        if not logger.handlers:
            handler = logging.FileHandler(self.config.LOGGING['file'], encoding='utf-8')
            formatter = logging.Formatter(self.config.LOGGING['format'])
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
    
    def apply_all_filters(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ëª¨ë“  í•„í„°ë§ ì ìš©
        Args:
            df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        Returns:
            í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
        """
        try:
            self.logger.info(f"ğŸ” ë°ì´í„° í•„í„°ë§ ì‹œì‘: {len(df):,}ê°œ ëŒ“ê¸€")
            self.filter_stats['original_count'] = len(df)
            
            filtered_df = df.copy()
            
            # 1. ì¶”ì²œìˆ˜ ê¸°ë°˜ í•„í„°ë§
            if self.filtering_config['upvote_filtering']['enabled']:
                filtered_df = self._apply_upvote_filter(filtered_df)
                self.filter_stats['upvote_filtered'] = self.filter_stats['original_count'] - len(filtered_df)
                self.logger.info(f"ğŸ“Š ì¶”ì²œìˆ˜ í•„í„°ë§ í›„: {len(filtered_df):,}ê°œ ëŒ“ê¸€ ({self.filter_stats['upvote_filtered']:,}ê°œ ì œê±°)")
            
            # 2. í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§
            if self.filtering_config['keyword_filtering']['enabled']:
                before_count = len(filtered_df)
                filtered_df = self._apply_keyword_filter(filtered_df)
                self.filter_stats['keyword_filtered'] = before_count - len(filtered_df)
                self.logger.info(f"ğŸ”‘ í‚¤ì›Œë“œ í•„í„°ë§ í›„: {len(filtered_df):,}ê°œ ëŒ“ê¸€ ({self.filter_stats['keyword_filtered']:,}ê°œ ì œê±°)")
            
            # 3. í’ˆì§ˆ ê¸°ë°˜ í•„í„°ë§
            if self.filtering_config['quality_filtering']['enabled']:
                before_count = len(filtered_df)
                filtered_df = self._apply_quality_filter(filtered_df)
                self.filter_stats['quality_filtered'] = before_count - len(filtered_df)
                self.logger.info(f"âœ¨ í’ˆì§ˆ í•„í„°ë§ í›„: {len(filtered_df):,}ê°œ ëŒ“ê¸€ ({self.filter_stats['quality_filtered']:,}ê°œ ì œê±°)")
            
            # 4. ì¤‘ë³µ ëŒ“ê¸€ í•„í„°ë§
            if self.filtering_config['duplicate_filtering']['enabled']:
                before_count = len(filtered_df)
                filtered_df = self._apply_duplicate_filter(filtered_df)
                self.filter_stats['duplicate_filtered'] = before_count - len(filtered_df)
                self.logger.info(f"ğŸ”„ ì¤‘ë³µ í•„í„°ë§ í›„: {len(filtered_df):,}ê°œ ëŒ“ê¸€ ({self.filter_stats['duplicate_filtered']:,}ê°œ ì œê±°)")
            
            # 5. ì‚¬ìš©ì ê¸°ë°˜ í•„í„°ë§
            if self.filtering_config['user_filtering']['enabled']:
                before_count = len(filtered_df)
                filtered_df = self._apply_user_filter(filtered_df)
                self.filter_stats['user_filtered'] = before_count - len(filtered_df)
                self.logger.info(f"ğŸ‘¤ ì‚¬ìš©ì í•„í„°ë§ í›„: {len(filtered_df):,}ê°œ ëŒ“ê¸€ ({self.filter_stats['user_filtered']:,}ê°œ ì œê±°)")
            
            self.filter_stats['final_count'] = len(filtered_df)
            
            # í•„í„°ë§ ê²°ê³¼ ìš”ì•½
            self._log_filtering_summary()
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ë°ì´í„° í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _apply_upvote_filter(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì¶”ì²œìˆ˜ ê¸°ë°˜ í•„í„°ë§
        Args:
            df: ë°ì´í„°í”„ë ˆì„
        Returns:
            í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
        """
        try:
            config = self.filtering_config['upvote_filtering']
            
            # upvotes ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if 'upvotes' not in df.columns:
                self.logger.warning("âš ï¸ upvotes ì»¬ëŸ¼ì´ ì—†ì–´ ì¶”ì²œìˆ˜ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return df
            
            # NaN ê°’ì„ 0ìœ¼ë¡œ ì²˜ë¦¬
            df['upvotes'] = df['upvotes'].fillna(0)
            
            # ìµœì†Œ ì¶”ì²œìˆ˜ í•„í„°ë§
            mask = df['upvotes'] >= config['min_upvotes']
            
            # ìˆœì¶”ì²œìˆ˜ í•„í„°ë§ (downvotes ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
            if 'downvotes' in df.columns and config['min_net_upvotes'] > 0:
                df['downvotes'] = df['downvotes'].fillna(0)
                net_upvotes = df['upvotes'] - df['downvotes']
                
                if config['use_net_upvotes_only_when_positive']:
                    # ìˆœì¶”ì²œìˆ˜ê°€ ì–‘ìˆ˜ì¸ ê²½ìš°ë§Œ í•„í„°ë§ ì ìš©
                    net_mask = (net_upvotes >= config['min_net_upvotes']) | (net_upvotes <= 0)
                else:
                    # ëª¨ë“  ê²½ìš°ì— ìˆœì¶”ì²œìˆ˜ í•„í„°ë§ ì ìš©
                    net_mask = net_upvotes >= config['min_net_upvotes']
                
                mask = mask & net_mask
            
            filtered_df = df[mask].copy()
            
            self.logger.info(f"ğŸ“Š ì¶”ì²œìˆ˜ í•„í„°ë§: ìµœì†Œ {config['min_upvotes']}ê°œ ì¶”ì²œ, "
                           f"ìµœì†Œ ìˆœì¶”ì²œ {config['min_net_upvotes']}ê°œ")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ì¶”ì²œìˆ˜ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _apply_keyword_filter(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§ (ê°•í™”ëœ ëª¨ë“œ ì§€ì›)
        - basic ëª¨ë“œ: ê¸°ì¡´ ë°©ì‹ (ì˜ìƒ ë‹¨ìœ„ í¬í•¨ í‚¤ì›Œë“œ + ëŒ“ê¸€ ë‹¨ìœ„ ì œì™¸ í‚¤ì›Œë“œ)
        - enhanced ëª¨ë“œ: ì œëª© í¬í•¨ OR ëŒ“ê¸€ ë¹„ìœ¨ ì¡°ê±´
        Args:
            df: ë°ì´í„°í”„ë ˆì„
        Returns:
            í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
        """
        try:
            config = self.filtering_config['keyword_filtering']
            
            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í™•ì¸
            text_column = None
            for col in ['comment_text', 'cleaned_text', 'text', 'content']:
                if col in df.columns:
                    text_column = col
                    break
            
            if text_column is None:
                self.logger.warning("âš ï¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ í‚¤ì›Œë“œ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return df
            
            # NaN ê°’ ì²˜ë¦¬
            df[text_column] = df[text_column].fillna('')
            
            # í•„í„°ë§ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
            filtering_mode = config.get('filtering_mode', 'basic')
            
            if filtering_mode == 'enhanced':
                # ğŸ”§ ê°•í™”ëœ í•„í„°ë§ ëª¨ë“œ
                filtered_df = self._apply_enhanced_keyword_filter(df, text_column, config)
            else:
                # ê¸°ë³¸ í•„í„°ë§ ëª¨ë“œ (ê¸°ì¡´ ë°©ì‹)
                filtered_df = self._apply_basic_keyword_filter(df, text_column, config)
            
            # 2ë‹¨ê³„: ëŒ“ê¸€ ë‹¨ìœ„ ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§ (ê³µí†µ)
            if config['excluded_keywords']:
                filtered_df = self._apply_comment_level_exclusion_filter(filtered_df, text_column, config)
                self.logger.info(f"ğŸš« ëŒ“ê¸€ ë‹¨ìœ„ ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§: {len(config['excluded_keywords'])}ê°œ í‚¤ì›Œë“œ")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ í‚¤ì›Œë“œ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _apply_video_level_keyword_filter(self, df: pd.DataFrame, text_column: str, config: Dict) -> pd.DataFrame:
        """
        ì˜ìƒ ë‹¨ìœ„ í•„ìˆ˜ í‚¤ì›Œë“œ í•„í„°ë§
        ì˜ìƒ ì œëª©ì´ë‚˜ í•´ë‹¹ ì˜ìƒì˜ ëŒ“ê¸€ ì¤‘ í•˜ë‚˜ë¼ë„ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ë©´ ê·¸ ì˜ìƒì˜ ëª¨ë“  ëŒ“ê¸€ì„ í¬í•¨
        """
        try:
            # ì˜ìƒ ì‹ë³„ ì»¬ëŸ¼ í™•ì¸
            video_id_column = None
            for col in ['video_no', 'video_id', 'video_url', 'url']:
                if col in df.columns:
                    video_id_column = col
                    break
            
            if video_id_column is None:
                self.logger.warning("âš ï¸ ì˜ìƒ ì‹ë³„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ëŒ“ê¸€ ë‹¨ìœ„ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤.")
                return self._apply_comment_level_keyword_filter(df, text_column, config)
            
            # ì˜ìƒ ì œëª© ì»¬ëŸ¼ í™•ì¸
            title_column = None
            for col in ['video_title', 'title', 'video_name']:
                if col in df.columns:
                    title_column = col
                    break
            
            valid_videos = set()
            
            # ê° ì˜ìƒë³„ë¡œ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
            for video_id, video_group in df.groupby(video_id_column):
                video_has_keyword = False
                
                # 1. ì˜ìƒ ì œëª©ì—ì„œ í‚¤ì›Œë“œ í™•ì¸
                if title_column and not video_group[title_column].isna().all():
                    video_title = str(video_group[title_column].iloc[0])
                    if self._text_contains_keywords(video_title, config['required_keywords'], config):
                        video_has_keyword = True
                        self.logger.debug(f"ğŸ“º ì˜ìƒ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ë°œê²¬: {video_id}")
                
                # 2. í•´ë‹¹ ì˜ìƒì˜ ëŒ“ê¸€ë“¤ì—ì„œ í‚¤ì›Œë“œ í™•ì¸
                if not video_has_keyword:
                    for comment_text in video_group[text_column]:
                        if self._text_contains_keywords(str(comment_text), config['required_keywords'], config):
                            video_has_keyword = True
                            self.logger.debug(f"ğŸ’¬ ì˜ìƒ ëŒ“ê¸€ì—ì„œ í‚¤ì›Œë“œ ë°œê²¬: {video_id}")
                            break
                
                # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì˜ìƒì„ ìœ íš¨ ëª©ë¡ì— ì¶”ê°€
                if video_has_keyword:
                    valid_videos.add(video_id)
            
            # ìœ íš¨í•œ ì˜ìƒì˜ ëª¨ë“  ëŒ“ê¸€ ë°˜í™˜
            filtered_df = df[df[video_id_column].isin(valid_videos)].copy()
            
            self.logger.info(f"ğŸ¬ ì˜ìƒ ë‹¨ìœ„ í•„í„°ë§ ê²°ê³¼: {len(valid_videos)}ê°œ ì˜ìƒì˜ {len(filtered_df)}ê°œ ëŒ“ê¸€")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ì˜ìƒ ë‹¨ìœ„ í‚¤ì›Œë“œ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _apply_comment_level_keyword_filter(self, df: pd.DataFrame, text_column: str, config: Dict) -> pd.DataFrame:
        """
        ëŒ“ê¸€ ë‹¨ìœ„ í•„ìˆ˜ í‚¤ì›Œë“œ í•„í„°ë§ (ì˜ìƒ ë‹¨ìœ„ í•„í„°ë§ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ëŒ€ì²´)
        """
        try:
            required_mask = pd.Series([False] * len(df), index=df.index)
            
            for keyword in config['required_keywords']:
                keyword_mask = self._create_keyword_mask(df[text_column], keyword, config)
                required_mask = required_mask | keyword_mask
            
            filtered_df = df[required_mask].copy()
            self.logger.info(f"ğŸ’¬ ëŒ“ê¸€ ë‹¨ìœ„ í•„ìˆ˜ í‚¤ì›Œë“œ í•„í„°ë§: {len(filtered_df)}ê°œ ëŒ“ê¸€")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ëŒ“ê¸€ ë‹¨ìœ„ í‚¤ì›Œë“œ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _apply_comment_level_exclusion_filter(self, df: pd.DataFrame, text_column: str, config: Dict) -> pd.DataFrame:
        """
        ëŒ“ê¸€ ë‹¨ìœ„ ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§
        ê°œë³„ ëŒ“ê¸€ì— ì œì™¸ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê·¸ ëŒ“ê¸€ë§Œ ì œì™¸
        """
        try:
            mask = pd.Series([True] * len(df), index=df.index)
            
            for keyword in config['excluded_keywords']:
                exclude_mask = ~self._create_keyword_mask(df[text_column], keyword, config)
                mask = mask & exclude_mask
            
            filtered_df = df[mask].copy()
            excluded_count = len(df) - len(filtered_df)
            
            self.logger.info(f"ğŸš« ëŒ“ê¸€ ë‹¨ìœ„ ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§: {excluded_count}ê°œ ëŒ“ê¸€ ì œì™¸")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ëŒ“ê¸€ ë‹¨ìœ„ ì œì™¸ í‚¤ì›Œë“œ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _text_contains_keywords(self, text: str, keywords: List[str], config: Dict) -> bool:
        """
        í…ìŠ¤íŠ¸ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        """
        try:
            if not isinstance(text, str) or not text.strip():
                return False
            
            for keyword in keywords:
                if self._text_contains_keyword(text, keyword, config):
                    return True
            
            return False
            
        except Exception as e:
            return False
    
    def _text_contains_keyword(self, text: str, keyword: str, config: Dict) -> bool:
        """
        í…ìŠ¤íŠ¸ì— íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        """
        try:
            if config['case_sensitive']:
                search_text = text
                search_keyword = keyword
            else:
                search_text = text.lower()
                search_keyword = keyword.lower()
            
            if config['partial_match']:
                return search_keyword in search_text
            else:
                # ì™„ì „ ë‹¨ì–´ ë§¤ì¹­
                import re
                pattern = f'\\b{re.escape(search_keyword)}\\b'
                return bool(re.search(pattern, search_text))
                
        except Exception as e:
            return False
    
    def _create_keyword_mask(self, text_series: pd.Series, keyword: str, config: Dict) -> pd.Series:
        """
        í‚¤ì›Œë“œì— ëŒ€í•œ ë§ˆìŠ¤í¬ ìƒì„±
        """
        try:
            if config['case_sensitive']:
                if config['partial_match']:
                    return text_series.str.contains(keyword, na=False, regex=False)
                else:
                    return text_series.str.contains(f'\\b{re.escape(keyword)}\\b', na=False, regex=True)
            else:
                if config['partial_match']:
                    return text_series.str.contains(keyword, case=False, na=False, regex=False)
                else:
                    return text_series.str.contains(f'\\b{re.escape(keyword)}\\b', case=False, na=False, regex=True)
                    
        except Exception as e:
            self.logger.error(f"âŒ í‚¤ì›Œë“œ ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return pd.Series([False] * len(text_series), index=text_series.index)
    
    def _apply_quality_filter(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        í’ˆì§ˆ ê¸°ë°˜ í•„í„°ë§
        Args:
            df: ë°ì´í„°í”„ë ˆì„
        Returns:
            í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
        """
        try:
            config = self.filtering_config['quality_filtering']
            
            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í™•ì¸
            text_column = None
            for col in ['comment_text', 'cleaned_text', 'text', 'content']:
                if col in df.columns:
                    text_column = col
                    break
            
            if text_column is None:
                self.logger.warning("âš ï¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ í’ˆì§ˆ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return df
            
            # NaN ê°’ ì²˜ë¦¬
            df[text_column] = df[text_column].fillna('')
            
            mask = pd.Series([True] * len(df), index=df.index)
            
            for idx, text in tqdm(df[text_column].items(), desc="í’ˆì§ˆ í•„í„°ë§", total=len(df)):
                if not isinstance(text, str) or len(text.strip()) == 0:
                    mask[idx] = False
                    continue
                
                # í•œ ê¸€ì ëŒ“ê¸€ ì œì™¸
                if config['exclude_single_char_comments'] and len(text.strip()) == 1:
                    mask[idx] = False
                    continue
                
                # í•œê¸€ ë¹„ìœ¨ í™•ì¸
                korean_chars = len(re.findall(r'[ê°€-í£]', text))
                total_chars = len(text)
                korean_ratio = korean_chars / total_chars if total_chars > 0 else 0
                
                if korean_ratio < config['min_korean_ratio']:
                    mask[idx] = False
                    continue
                
                # íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨ í™•ì¸
                special_chars = len(re.findall(r'[^\w\sê°€-í£]', text))
                special_ratio = special_chars / total_chars if total_chars > 0 else 0
                
                if special_ratio > config['max_special_char_ratio']:
                    mask[idx] = False
                    continue
                
                # ë°˜ë³µ ë¬¸ì ë¹„ìœ¨ í™•ì¸
                repeated_chars = 0
                for char in set(text):
                    if char != ' ':
                        char_count = text.count(char)
                        if char_count > 3:  # 3ë²ˆ ì´ìƒ ë°˜ë³µë˜ëŠ” ë¬¸ì
                            repeated_chars += char_count - 3
                
                repeated_ratio = repeated_chars / total_chars if total_chars > 0 else 0
                
                if repeated_ratio > config['max_repeated_char_ratio']:
                    mask[idx] = False
                    continue
                
                # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ ìˆ˜ í™•ì¸
                words = re.findall(r'[ê°€-í£a-zA-Z]+', text)
                meaningful_words = [word for word in words if len(word) > 1]
                
                if len(meaningful_words) < config['min_meaningful_words']:
                    mask[idx] = False
                    continue
                
                # ì´ëª¨ì§€ë§Œ ìˆëŠ” ëŒ“ê¸€ ì œì™¸
                if config['exclude_emoji_only_comments']:
                    # ì´ëª¨ì§€ íŒ¨í„´ (ê°„ë‹¨í•œ ë²„ì „)
                    emoji_pattern = re.compile(
                        "["
                        "\U0001F600-\U0001F64F"  # emoticons
                        "\U0001F300-\U0001F5FF"  # symbols & pictographs
                        "\U0001F680-\U0001F6FF"  # transport & map symbols
                        "\U0001F1E0-\U0001F1FF"  # flags (iOS)
                        "\U00002702-\U000027B0"
                        "\U000024C2-\U0001F251"
                        "]+", flags=re.UNICODE
                    )
                    
                    text_without_emoji = emoji_pattern.sub('', text).strip()
                    if len(text_without_emoji) == 0:
                        mask[idx] = False
                        continue
            
            filtered_df = df[mask].copy()
            
            self.logger.info(f"âœ¨ í’ˆì§ˆ í•„í„°ë§: í•œê¸€ë¹„ìœ¨ {config['min_korean_ratio']:.1%} ì´ìƒ, "
                           f"íŠ¹ìˆ˜ë¬¸ì {config['max_special_char_ratio']:.1%} ì´í•˜, "
                           f"ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ {config['min_meaningful_words']}ê°œ ì´ìƒ")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ í’ˆì§ˆ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _apply_duplicate_filter(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì¤‘ë³µ ëŒ“ê¸€ í•„í„°ë§
        Args:
            df: ë°ì´í„°í”„ë ˆì„
        Returns:
            í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
        """
        try:
            config = self.filtering_config['duplicate_filtering']
            
            # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í™•ì¸
            text_column = None
            for col in ['comment_text', 'cleaned_text', 'text', 'content']:
                if col in df.columns:
                    text_column = col
                    break
            
            if text_column is None:
                self.logger.warning("âš ï¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¤‘ë³µ í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return df
            
            # NaN ê°’ ì²˜ë¦¬
            df[text_column] = df[text_column].fillna('')
            
            if config['exact_match_only']:
                # ì™„ì „ ì¼ì¹˜ ì¤‘ë³µ ì œê±°
                if config['keep_highest_upvotes'] and 'upvotes' in df.columns:
                    # ì¶”ì²œìˆ˜ê°€ ë†’ì€ ê²ƒ ìœ ì§€
                    df_sorted = df.sort_values('upvotes', ascending=False)
                    filtered_df = df_sorted.drop_duplicates(subset=[text_column], keep='first')
                else:
                    # ì²« ë²ˆì§¸ ê²ƒ ìœ ì§€
                    filtered_df = df.drop_duplicates(subset=[text_column], keep='first')
            else:
                # ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°
                filtered_df = self._remove_similar_duplicates(df, text_column, config)
            
            filter_type = 'ì™„ì „ì¼ì¹˜' if config['exact_match_only'] else f"ìœ ì‚¬ë„ {config['similarity_threshold']:.1%}"
            self.logger.info(f"ğŸ”„ ì¤‘ë³µ í•„í„°ë§: {filter_type} ê¸°ì¤€")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ì¤‘ë³µ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _remove_similar_duplicates(self, df: pd.DataFrame, text_column: str, config: Dict) -> pd.DataFrame:
        """
        ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°
        Args:
            df: ë°ì´í„°í”„ë ˆì„
            text_column: í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
            config: ì¤‘ë³µ í•„í„°ë§ ì„¤ì •
        Returns:
            ì¤‘ë³µ ì œê±°ëœ ë°ì´í„°í”„ë ˆì„
        """
        try:
            texts = df[text_column].tolist()
            indices_to_keep = []
            processed_indices = set()
            
            for i, text1 in enumerate(tqdm(texts, desc="ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±°")):
                if i in processed_indices:
                    continue
                
                # í˜„ì¬ í…ìŠ¤íŠ¸ì™€ ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë“¤ ì°¾ê¸°
                similar_indices = [i]
                
                for j, text2 in enumerate(texts[i+1:], start=i+1):
                    if j in processed_indices:
                        continue
                    
                    # ìœ ì‚¬ë„ ê³„ì‚°
                    similarity = difflib.SequenceMatcher(None, text1, text2).ratio()
                    
                    if similarity >= config['similarity_threshold']:
                        similar_indices.append(j)
                        processed_indices.add(j)
                
                # ìœ ì‚¬í•œ ëŒ“ê¸€ë“¤ ì¤‘ì—ì„œ í•˜ë‚˜ ì„ íƒ
                if config['keep_highest_upvotes'] and 'upvotes' in df.columns:
                    # ì¶”ì²œìˆ˜ê°€ ê°€ì¥ ë†’ì€ ê²ƒ ì„ íƒ
                    best_idx = max(similar_indices, key=lambda x: df.iloc[x]['upvotes'])
                else:
                    # ì²« ë²ˆì§¸ ê²ƒ ì„ íƒ
                    best_idx = similar_indices[0]
                
                indices_to_keep.append(best_idx)
                processed_indices.add(i)
            
            filtered_df = df.iloc[indices_to_keep].copy()
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ìœ ì‚¬ë„ ê¸°ë°˜ ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _apply_user_filter(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì‚¬ìš©ì ê¸°ë°˜ í•„í„°ë§
        Args:
            df: ë°ì´í„°í”„ë ˆì„
        Returns:
            í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
        """
        try:
            config = self.filtering_config['user_filtering']
            
            # ì‚¬ìš©ì ì»¬ëŸ¼ í™•ì¸
            user_column = None
            for col in ['author_name', 'user_name', 'username', 'author']:
                if col in df.columns:
                    user_column = col
                    break
            
            if user_column is None:
                self.logger.warning("âš ï¸ ì‚¬ìš©ì ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì‚¬ìš©ì í•„í„°ë§ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                return df
            
            # NaN ê°’ ì²˜ë¦¬
            df[user_column] = df[user_column].fillna('Unknown')
            
            mask = pd.Series([True] * len(df), index=df.index)
            
            # ì œì™¸í•  ì‚¬ìš©ì í•„í„°ë§
            if config['exclude_users']:
                exclude_mask = ~df[user_column].isin(config['exclude_users'])
                mask = mask & exclude_mask
            
            # ì‚¬ìš©ìë³„ ëŒ“ê¸€ ìˆ˜ ì œí•œ
            user_counts = df[user_column].value_counts()
            
            # ìµœì†Œ ëŒ“ê¸€ ìˆ˜ í•„í„°ë§
            valid_users = user_counts[user_counts >= config['min_user_comments']].index
            min_mask = df[user_column].isin(valid_users)
            mask = mask & min_mask
            
            # ìµœëŒ€ ëŒ“ê¸€ ìˆ˜ ì œí•œ (ìŠ¤íŒ¸ ë°©ì§€)
            if config['max_user_comments'] > 0:
                spam_users = user_counts[user_counts > config['max_user_comments']].index
                
                # ìŠ¤íŒ¸ ì‚¬ìš©ìì˜ ëŒ“ê¸€ ì¤‘ ì¼ë¶€ë§Œ ìœ ì§€ (ì¶”ì²œìˆ˜ ê¸°ì¤€)
                for user in spam_users:
                    user_comments = df[df[user_column] == user]
                    if 'upvotes' in df.columns:
                        # ì¶”ì²œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ëŒ“ê¸€ë§Œ ìœ ì§€
                        top_comments = user_comments.nlargest(config['max_user_comments'], 'upvotes')
                    else:
                        # ëœë¤í•˜ê²Œ ì„ íƒ
                        top_comments = user_comments.sample(n=config['max_user_comments'])
                    
                    # í•´ë‹¹ ì‚¬ìš©ìì˜ ë‹¤ë¥¸ ëŒ“ê¸€ë“¤ì€ ì œì™¸
                    user_mask = (df[user_column] != user) | df.index.isin(top_comments.index)
                    mask = mask & user_mask
            
            filtered_df = df[mask].copy()
            
            self.logger.info(f"ğŸ‘¤ ì‚¬ìš©ì í•„í„°ë§: ì‚¬ìš©ìë‹¹ {config['min_user_comments']}-{config['max_user_comments']}ê°œ ëŒ“ê¸€")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ì‚¬ìš©ì í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _log_filtering_summary(self):
        """í•„í„°ë§ ê²°ê³¼ ìš”ì•½ ë¡œê¹…"""
        try:
            stats = self.filter_stats
            total_removed = stats['original_count'] - stats['final_count']
            removal_rate = (total_removed / stats['original_count']) * 100 if stats['original_count'] > 0 else 0
            
            self.logger.info("=" * 60)
            self.logger.info("ğŸ“Š ë°ì´í„° í•„í„°ë§ ê²°ê³¼ ìš”ì•½")
            self.logger.info("=" * 60)
            self.logger.info(f"ğŸ“¥ ì›ë³¸ ëŒ“ê¸€ ìˆ˜: {stats['original_count']:,}ê°œ")
            self.logger.info(f"ğŸ“Š ì¶”ì²œìˆ˜ í•„í„°ë§: {stats['upvote_filtered']:,}ê°œ ì œê±°")
            self.logger.info(f"ğŸ”‘ í‚¤ì›Œë“œ í•„í„°ë§: {stats['keyword_filtered']:,}ê°œ ì œê±°")
            self.logger.info(f"âœ¨ í’ˆì§ˆ í•„í„°ë§: {stats['quality_filtered']:,}ê°œ ì œê±°")
            self.logger.info(f"ğŸ”„ ì¤‘ë³µ í•„í„°ë§: {stats['duplicate_filtered']:,}ê°œ ì œê±°")
            self.logger.info(f"ğŸ‘¤ ì‚¬ìš©ì í•„í„°ë§: {stats['user_filtered']:,}ê°œ ì œê±°")
            self.logger.info("-" * 60)
            self.logger.info(f"ğŸ“¤ ìµœì¢… ëŒ“ê¸€ ìˆ˜: {stats['final_count']:,}ê°œ")
            self.logger.info(f"ğŸ—‘ï¸ ì´ ì œê±°ëœ ëŒ“ê¸€: {total_removed:,}ê°œ ({removal_rate:.1f}%)")
            self.logger.info(f"âœ… ë°ì´í„° í’ˆì§ˆ í–¥ìƒë¥ : {100 - removal_rate:.1f}%")
            self.logger.info("=" * 60)
            
        except Exception as e:
            self.logger.error(f"âŒ í•„í„°ë§ ìš”ì•½ ë¡œê¹… ì‹¤íŒ¨: {str(e)}")
    
    def get_filtering_stats(self) -> Dict:
        """
        í•„í„°ë§ í†µê³„ ë°˜í™˜
        Returns:
            í•„í„°ë§ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        return self.filter_stats.copy()
    
    def validate_filtering_config(self) -> bool:
        """
        í•„í„°ë§ ì„¤ì • ê²€ì¦
        Returns:
            ì„¤ì •ì´ ìœ íš¨í•œì§€ ì—¬ë¶€
        """
        try:
            config = self.filtering_config
            self.logger.debug(f"ğŸ” í•„í„°ë§ ì„¤ì • ê²€ì¦ ì‹œì‘: {list(config.keys())}")
            
            # ì¶”ì²œìˆ˜ í•„í„°ë§ ê²€ì¦
            upvote_config = config['upvote_filtering']
            self.logger.debug(f"ğŸ“Š ì¶”ì²œìˆ˜ í•„í„°ë§ ì„¤ì •: {upvote_config}")
            if upvote_config['min_upvotes'] < 0:
                self.logger.error("âŒ ìµœì†Œ ì¶”ì²œìˆ˜ëŠ” 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
                return False
            
            # í‚¤ì›Œë“œ í•„í„°ë§ ê²€ì¦
            keyword_config = config['keyword_filtering']
            self.logger.debug(f"ğŸ”‘ í‚¤ì›Œë“œ í•„í„°ë§ ì„¤ì •: {list(keyword_config.keys())}")
            
            # basic_conditions ë‚´ì˜ min_keyword_matches í™•ì¸
            basic_conditions = keyword_config.get('basic_conditions', {})
            self.logger.debug(f"ğŸ”§ basic_conditions: {basic_conditions}")
            
            if 'min_keyword_matches' in basic_conditions:
                if basic_conditions['min_keyword_matches'] < 1:
                    self.logger.error("âŒ ìµœì†Œ í‚¤ì›Œë“œ ë§¤ì¹­ ìˆ˜ëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
                    return False
            else:
                self.logger.warning("âš ï¸ basic_conditionsì— min_keyword_matchesê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # í’ˆì§ˆ í•„í„°ë§ ê²€ì¦
            quality_config = config['quality_filtering']
            self.logger.debug(f"âœ¨ í’ˆì§ˆ í•„í„°ë§ ì„¤ì •: {list(quality_config.keys())}")
            if not (0 <= quality_config['min_korean_ratio'] <= 1):
                self.logger.error("âŒ ìµœì†Œ í•œê¸€ ë¹„ìœ¨ì€ 0-1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
                return False
            
            if not (0 <= quality_config['max_special_char_ratio'] <= 1):
                self.logger.error("âŒ ìµœëŒ€ íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨ì€ 0-1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
                return False
            
            # ì¤‘ë³µ í•„í„°ë§ ê²€ì¦
            duplicate_config = config['duplicate_filtering']
            self.logger.debug(f"ğŸ”„ ì¤‘ë³µ í•„í„°ë§ ì„¤ì •: {list(duplicate_config.keys())}")
            if not (0 <= duplicate_config['similarity_threshold'] <= 1):
                self.logger.error("âŒ ìœ ì‚¬ë„ ì„ê³„ê°’ì€ 0-1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
                return False
            
            self.logger.info("âœ… í•„í„°ë§ ì„¤ì • ê²€ì¦ ì™„ë£Œ")
            return True
            
        except KeyError as e:
            self.logger.error(f"âŒ í•„í„°ë§ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
            self.logger.error(f"ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ì„¤ì • í‚¤: {list(self.filtering_config.keys()) if hasattr(self, 'filtering_config') else 'filtering_config ì—†ìŒ'}")
            return False
        except Exception as e:
            self.logger.error(f"âŒ í•„í„°ë§ ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _apply_enhanced_keyword_filter(self, df: pd.DataFrame, text_column: str, config: Dict) -> pd.DataFrame:
        """
        ê°•í™”ëœ í‚¤ì›Œë“œ í•„í„°ë§
        ì¡°ê±´ 1: ì œëª©ì— í‚¤ì›Œë“œ í¬í•¨ OR ì¡°ê±´ 2: ëŒ“ê¸€ë“¤ ì¤‘ ìµœì†Œ ë¹„ìœ¨ ì´ìƒì´ í‚¤ì›Œë“œ í¬í•¨
        """
        try:
            enhanced_config = config.get('enhanced_conditions', {})
            
            # ì˜ìƒ ì‹ë³„ ì»¬ëŸ¼ í™•ì¸
            video_id_column = None
            for col in ['video_no', 'video_id', 'video_url', 'url']:
                if col in df.columns:
                    video_id_column = col
                    break
            
            if video_id_column is None:
                self.logger.warning("âš ï¸ ì˜ìƒ ì‹ë³„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ëŒ“ê¸€ ë‹¨ìœ„ë¡œ í•„í„°ë§í•©ë‹ˆë‹¤.")
                return self._apply_comment_level_keyword_filter(df, text_column, config)
            
            valid_videos = set()
            
            # ê° ì˜ìƒë³„ë¡œ ê°•í™”ëœ ì¡°ê±´ í™•ì¸
            for video_id, video_group in df.groupby(video_id_column):
                video_passes = False
                
                # ì¡°ê±´ 1: ì œëª©ì— í‚¤ì›Œë“œ í¬í•¨ í™•ì¸
                title_condition = enhanced_config.get('title_contains_keywords', {})
                if title_condition.get('enabled', False):
                    title_column = title_condition.get('title_column', 'video_title')
                    title_keywords = title_condition.get('keywords', config.get('required_keywords', []))
                    
                    if title_column in df.columns and not video_group[title_column].isna().all():
                        video_title = str(video_group[title_column].iloc[0])
                        if self._text_contains_keywords(video_title, title_keywords, config):
                            video_passes = True
                            self.logger.debug(f"ğŸ“º ì˜ìƒ ì œëª© ì¡°ê±´ í†µê³¼: {video_id}")
                
                # ì¡°ê±´ 2: ëŒ“ê¸€ ë¹„ìœ¨ ì¡°ê±´ í™•ì¸ (ì¡°ê±´ 1ì´ ì‹¤íŒ¨í•œ ê²½ìš°ì—ë§Œ)
                if not video_passes:
                    ratio_condition = enhanced_config.get('comment_ratio_threshold', {})
                    if ratio_condition.get('enabled', False):
                        min_ratio = ratio_condition.get('min_ratio', 0.40)
                        ratio_keywords = ratio_condition.get('keywords', config.get('required_keywords', []))
                        
                        # í•´ë‹¹ ì˜ìƒì˜ ëŒ“ê¸€ë“¤ ì¤‘ í‚¤ì›Œë“œ í¬í•¨ ë¹„ìœ¨ ê³„ì‚°
                        total_comments = len(video_group)
                        keyword_comments = 0
                        
                        for comment_text in video_group[text_column]:
                            if self._text_contains_keywords(str(comment_text), ratio_keywords, config):
                                keyword_comments += 1
                        
                        if total_comments > 0:
                            keyword_ratio = keyword_comments / total_comments
                            if keyword_ratio >= min_ratio:
                                video_passes = True
                                self.logger.debug(f"ğŸ’¬ ëŒ“ê¸€ ë¹„ìœ¨ ì¡°ê±´ í†µê³¼: {video_id} ({keyword_ratio:.1%} >= {min_ratio:.1%})")
                
                # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì˜ìƒì„ ìœ íš¨ ëª©ë¡ì— ì¶”ê°€
                if video_passes:
                    valid_videos.add(video_id)
            
            # ìœ íš¨í•œ ì˜ìƒì˜ ëª¨ë“  ëŒ“ê¸€ ë°˜í™˜
            filtered_df = df[df[video_id_column].isin(valid_videos)].copy()
            
            self.logger.info(f"ğŸ”§ ê°•í™”ëœ í‚¤ì›Œë“œ í•„í„°ë§ ê²°ê³¼: {len(valid_videos)}ê°œ ì˜ìƒì˜ {len(filtered_df)}ê°œ ëŒ“ê¸€")
            
            # ì¡°ê±´ë³„ í†µê³„ ë¡œê¹…
            title_condition = enhanced_config.get('title_contains_keywords', {})
            ratio_condition = enhanced_config.get('comment_ratio_threshold', {})
            
            if title_condition.get('enabled', False):
                self.logger.info(f"  ğŸ“º ì œëª© ì¡°ê±´: {title_condition.get('title_column', 'video_title')} ì»¬ëŸ¼ì—ì„œ í‚¤ì›Œë“œ í™•ì¸")
            
            if ratio_condition.get('enabled', False):
                min_ratio = ratio_condition.get('min_ratio', 0.40)
                self.logger.info(f"  ğŸ’¬ ëŒ“ê¸€ ë¹„ìœ¨ ì¡°ê±´: ìµœì†Œ {min_ratio:.1%} ì´ìƒì˜ ëŒ“ê¸€ì´ í‚¤ì›Œë“œ í¬í•¨")
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ê°•í™”ëœ í‚¤ì›Œë“œ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df
    
    def _apply_basic_keyword_filter(self, df: pd.DataFrame, text_column: str, config: Dict) -> pd.DataFrame:
        """
        ê¸°ë³¸ í‚¤ì›Œë“œ í•„í„°ë§ (ê¸°ì¡´ ë°©ì‹)
        """
        try:
            # 1ë‹¨ê³„: ì˜ìƒ ë‹¨ìœ„ í•„ìˆ˜ í‚¤ì›Œë“œ í•„í„°ë§
            if config['required_keywords']:
                filtered_df = self._apply_video_level_keyword_filter(df, text_column, config)
                self.logger.info(f"ğŸ¬ ì˜ìƒ ë‹¨ìœ„ í‚¤ì›Œë“œ í•„í„°ë§: {len(config['required_keywords'])}ê°œ í‚¤ì›Œë“œ ê¸°ì¤€")
            else:
                filtered_df = df.copy()
            
            return filtered_df
            
        except Exception as e:
            self.logger.error(f"âŒ ê¸°ë³¸ í‚¤ì›Œë“œ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            return df 