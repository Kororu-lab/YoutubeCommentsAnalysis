"""
Report Generator Module
ë³´ê³ ì„œ ìƒì„± ëª¨ë“ˆ
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Tuple, Optional
import os
import json
from datetime import datetime
from jinja2 import Template

class ReportGenerator:
    """ë³´ê³ ì„œ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, config):
        """
        ì´ˆê¸°í™”
        Args:
            config: AnalysisConfig ê°ì²´
        """
        self.config = config
        self.logger = self._setup_logger()
        self.output_dir = config.OUTPUT_STRUCTURE['reports']
        
    def _setup_logger(self):
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger(__name__)
        logger.setLevel(getattr(logging, self.config.LOGGING['level']))
        
        if not logger.handlers:
            handler = logging.FileHandler(self.config.LOGGING['file'], encoding='utf-8')
            formatter = logging.Formatter(self.config.LOGGING['format'])
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
    
    def generate_comprehensive_report(self, all_results: Dict, target_name: str) -> str:
        """
        ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„±
        Args:
            all_results: ëª¨ë“  ë¶„ì„ ê²°ê³¼
            target_name: ë¶„ì„ ëŒ€ìƒ ì´ë¦„
        Returns:
            ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ
        """
        try:
            self.logger.info(f"ğŸ“‹ {target_name} ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì‹œì‘")
            
            # ë³´ê³ ì„œ ë‚´ìš© êµ¬ì„±
            report_content = self._build_report_content(all_results, target_name)
            
            # HTML ë³´ê³ ì„œ ìƒì„±
            html_report = self._generate_html_report(report_content, target_name)
            
            # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±
            md_report = self._generate_markdown_report(report_content, target_name)
            
            # JSON ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
            json_summary = self._generate_json_summary(all_results, target_name)
            
            self.logger.info(f"âœ… {target_name} ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
            return html_report
            
        except Exception as e:
            self.logger.error(f"âŒ {target_name} ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _build_report_content(self, all_results: Dict, target_name: str) -> Dict:
        """ë³´ê³ ì„œ ë‚´ìš© êµ¬ì„±"""
        try:
            # ê¸°ë³¸ ì •ë³´
            total_comments = sum(result.get('total_comments', 0) for result in all_results.values())
            analysis_period = {
                'start': min(all_results.keys()) if all_results else 'N/A',
                'end': max(all_results.keys()) if all_results else 'N/A',
                'total_months': len(all_results)
            }
            
            # ê°ì„± ë¶„ì„ ìš”ì•½
            sentiment_summary = self._summarize_sentiment_analysis(all_results)
            
            # í† í”½ ë¶„ì„ ìš”ì•½
            topic_summary = self._summarize_topic_analysis(all_results)
            
            # ì‹œê°„ì  ë³€í™” ë¶„ì„
            temporal_analysis = self._analyze_temporal_changes(all_results)
            
            # ì£¼ìš” ë°œê²¬ì‚¬í•­
            key_findings = self._extract_key_findings(all_results, target_name)
            
            # ì—°êµ¬ í•¨ì˜
            research_implications = self._generate_research_implications(all_results, target_name)
            
            return {
                'target_name': target_name,
                'analysis_date': datetime.now().strftime('%Yë…„ %mì›” %dì¼'),
                'total_comments': total_comments,
                'analysis_period': analysis_period,
                'sentiment_summary': sentiment_summary,
                'topic_summary': topic_summary,
                'temporal_analysis': temporal_analysis,
                'key_findings': key_findings,
                'research_implications': research_implications
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ë³´ê³ ì„œ ë‚´ìš© êµ¬ì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _summarize_sentiment_analysis(self, all_results: Dict) -> Dict:
        """ê°ì„± ë¶„ì„ ìš”ì•½"""
        try:
            if not all_results:
                return {'error': 'ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'}
            
            # ì „ì²´ ê¸°ê°„ ê°ì„± í†µê³„
            total_positive = 0
            total_negative = 0
            total_comments = 0
            
            monthly_sentiments = []
            emotion_distributions = []
            
            for month, result in all_results.items():
                if 'binary_sentiment' in result:
                    binary_data = result['binary_sentiment']
                    pos_count = binary_data.get('positive_count', 0)
                    neg_count = binary_data.get('negative_count', 0)
                    
                    total_positive += pos_count
                    total_negative += neg_count
                    total_comments += result.get('total_comments', 0)
                    
                    monthly_sentiments.append({
                        'month': month,
                        'positive_ratio': binary_data.get('positive_ratio', 0),
                        'negative_ratio': binary_data.get('negative_ratio', 0)
                    })
                
                if 'emotion_sentiment' in result:
                    emotion_data = result['emotion_sentiment']
                    emotion_distributions.append({
                        'month': month,
                        'dominant_emotion': emotion_data.get('dominant_emotion', 'ì—†ìŒ'),
                        'distribution': emotion_data.get('emotion_distribution', {})
                    })
            
            # ì „ì²´ ê°ì„± ë¹„ìœ¨
            overall_positive_ratio = total_positive / total_comments if total_comments > 0 else 0
            overall_negative_ratio = total_negative / total_comments if total_comments > 0 else 0
            
            # ê°ì„± ë³€í™” íŠ¸ë Œë“œ
            if len(monthly_sentiments) > 1:
                first_month = monthly_sentiments[0]
                last_month = monthly_sentiments[-1]
                
                positive_change = last_month['positive_ratio'] - first_month['positive_ratio']
                negative_change = last_month['negative_ratio'] - first_month['negative_ratio']
                
                trend_analysis = {
                    'positive_trend': 'ì¦ê°€' if positive_change > 0.05 else 'ê°ì†Œ' if positive_change < -0.05 else 'ì•ˆì •',
                    'negative_trend': 'ì¦ê°€' if negative_change > 0.05 else 'ê°ì†Œ' if negative_change < -0.05 else 'ì•ˆì •',
                    'positive_change': positive_change,
                    'negative_change': negative_change
                }
            else:
                trend_analysis = {'message': 'íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}
            
            # ì£¼ìš” ê°ì • ë¶„ì„
            all_emotions = {}
            for emotion_data in emotion_distributions:
                for emotion, ratio in emotion_data['distribution'].items():
                    if emotion not in all_emotions:
                        all_emotions[emotion] = []
                    all_emotions[emotion].append(ratio)
            
            avg_emotions = {emotion: np.mean(ratios) for emotion, ratios in all_emotions.items()}
            dominant_overall_emotion = max(avg_emotions.items(), key=lambda x: x[1])[0] if avg_emotions else 'ì—†ìŒ'
            
            return {
                'overall_statistics': {
                    'total_comments': total_comments,
                    'positive_ratio': overall_positive_ratio,
                    'negative_ratio': overall_negative_ratio,
                    'dominant_emotion': dominant_overall_emotion
                },
                'trend_analysis': trend_analysis,
                'monthly_data': monthly_sentiments,
                'emotion_analysis': {
                    'average_distribution': avg_emotions,
                    'monthly_emotions': emotion_distributions
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ê°ì„± ë¶„ì„ ìš”ì•½ ì‹¤íŒ¨: {str(e)}")
            return {'error': str(e)}
    
    def _summarize_topic_analysis(self, all_results: Dict) -> Dict:
        """í† í”½ ë¶„ì„ ìš”ì•½"""
        try:
            if not all_results:
                return {'error': 'ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.'}
            
            bertopic_results = []
            lda_results = []
            
            for month, result in all_results.items():
                # BERTopic ê²°ê³¼
                if 'bertopic' in result and result['bertopic']:
                    bertopic_data = result['bertopic']
                    bertopic_results.append({
                        'month': month,
                        'topic_count': len(bertopic_data.get('topic_labels', [])),
                        'main_topics': bertopic_data.get('topic_labels', [])[:3]  # ìƒìœ„ 3ê°œ
                    })
                
                # LDA ê²°ê³¼
                if 'lda' in result and result['lda']:
                    lda_data = result['lda']
                    lda_results.append({
                        'month': month,
                        'topic_count': len(lda_data.get('topic_labels', [])),
                        'coherence_score': lda_data.get('coherence_score', 0),
                        'main_topics': lda_data.get('topic_labels', [])[:3]  # ìƒìœ„ 3ê°œ
                    })
            
            # í† í”½ ì§„í™” ë¶„ì„
            topic_evolution = self._analyze_topic_evolution(bertopic_results, lda_results)
            
            # ì£¼ìš” í† í”½ ì¶”ì¶œ
            all_bertopic_topics = []
            all_lda_topics = []
            
            for result in bertopic_results:
                all_bertopic_topics.extend(result['main_topics'])
            
            for result in lda_results:
                all_lda_topics.extend(result['main_topics'])
            
            # í† í”½ ë¹ˆë„ ê³„ì‚°
            from collections import Counter
            bertopic_freq = Counter(all_bertopic_topics)
            lda_freq = Counter(all_lda_topics)
            
            return {
                'bertopic_analysis': {
                    'monthly_results': bertopic_results,
                    'frequent_topics': bertopic_freq.most_common(5),
                    'avg_topics_per_month': np.mean([r['topic_count'] for r in bertopic_results]) if bertopic_results else 0
                },
                'lda_analysis': {
                    'monthly_results': lda_results,
                    'frequent_topics': lda_freq.most_common(5),
                    'avg_topics_per_month': np.mean([r['topic_count'] for r in lda_results]) if lda_results else 0,
                    'avg_coherence': np.mean([r['coherence_score'] for r in lda_results]) if lda_results else 0
                },
                'topic_evolution': topic_evolution
            }
            
        except Exception as e:
            self.logger.error(f"âŒ í† í”½ ë¶„ì„ ìš”ì•½ ì‹¤íŒ¨: {str(e)}")
            return {'error': str(e)}
    
    def _analyze_topic_evolution(self, bertopic_results: List, lda_results: List) -> Dict:
        """í† í”½ ì§„í™” ë¶„ì„"""
        try:
            evolution_analysis = {}
            
            # BERTopic ì§„í™”
            if len(bertopic_results) > 1:
                topic_counts = [r['topic_count'] for r in bertopic_results]
                evolution_analysis['bertopic_trend'] = {
                    'trend': 'ì¦ê°€' if topic_counts[-1] > topic_counts[0] else 'ê°ì†Œ' if topic_counts[-1] < topic_counts[0] else 'ì•ˆì •',
                    'change': topic_counts[-1] - topic_counts[0],
                    'volatility': np.std(topic_counts)
                }
            
            # LDA ì§„í™”
            if len(lda_results) > 1:
                topic_counts = [r['topic_count'] for r in lda_results]
                coherence_scores = [r['coherence_score'] for r in lda_results]
                
                evolution_analysis['lda_trend'] = {
                    'topic_trend': 'ì¦ê°€' if topic_counts[-1] > topic_counts[0] else 'ê°ì†Œ' if topic_counts[-1] < topic_counts[0] else 'ì•ˆì •',
                    'coherence_trend': 'ì¦ê°€' if coherence_scores[-1] > coherence_scores[0] else 'ê°ì†Œ' if coherence_scores[-1] < coherence_scores[0] else 'ì•ˆì •',
                    'topic_change': topic_counts[-1] - topic_counts[0],
                    'coherence_change': coherence_scores[-1] - coherence_scores[0]
                }
            
            return evolution_analysis
            
        except Exception as e:
            self.logger.error(f"âŒ í† í”½ ì§„í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {'error': str(e)}
    
    def _analyze_temporal_changes(self, all_results: Dict) -> Dict:
        """ì‹œê°„ì  ë³€í™” ë¶„ì„"""
        try:
            if len(all_results) < 2:
                return {'message': 'ì‹œê°„ì  ë³€í™” ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}
            
            months = sorted(all_results.keys())
            
            # ëŒ“ê¸€ ìˆ˜ ë³€í™”
            comment_counts = [all_results[month].get('total_comments', 0) for month in months]
            
            # ê°ì„± ë³€í™”
            positive_ratios = []
            negative_ratios = []
            
            for month in months:
                if 'binary_sentiment' in all_results[month]:
                    binary_data = all_results[month]['binary_sentiment']
                    positive_ratios.append(binary_data.get('positive_ratio', 0))
                    negative_ratios.append(binary_data.get('negative_ratio', 0))
                else:
                    positive_ratios.append(0)
                    negative_ratios.append(0)
            
            # ë³€í™”ìœ¨ ê³„ì‚°
            comment_changes = [comment_counts[i] - comment_counts[i-1] for i in range(1, len(comment_counts))]
            positive_changes = [positive_ratios[i] - positive_ratios[i-1] for i in range(1, len(positive_ratios))]
            negative_changes = [negative_ratios[i] - negative_ratios[i-1] for i in range(1, len(negative_ratios))]
            
            # ì£¼ìš” ë³€í™” ì‹œì  ì‹ë³„
            significant_changes = []
            
            # ëŒ“ê¸€ ìˆ˜ ê¸‰ì¦/ê¸‰ê° ì‹œì 
            for i, change in enumerate(comment_changes):
                if abs(change) > np.std(comment_changes) * 2:  # 2 í‘œì¤€í¸ì°¨ ì´ìƒ
                    significant_changes.append({
                        'month': months[i+1],
                        'type': 'ëŒ“ê¸€ ìˆ˜ ê¸‰ì¦' if change > 0 else 'ëŒ“ê¸€ ìˆ˜ ê¸‰ê°',
                        'change': change,
                        'description': f'ì „ì›” ëŒ€ë¹„ {abs(change):,}ê°œ {"ì¦ê°€" if change > 0 else "ê°ì†Œ"}'
                    })
            
            # ê°ì„± ê¸‰ë³€ ì‹œì 
            for i, (pos_change, neg_change) in enumerate(zip(positive_changes, negative_changes)):
                if abs(pos_change) > 0.1 or abs(neg_change) > 0.1:  # 10% ì´ìƒ ë³€í™”
                    significant_changes.append({
                        'month': months[i+1],
                        'type': 'ê°ì„± ê¸‰ë³€',
                        'positive_change': pos_change,
                        'negative_change': neg_change,
                        'description': f'ê¸ì • ê°ì„± {pos_change:+.1%}, ë¶€ì • ê°ì„± {neg_change:+.1%} ë³€í™”'
                    })
            
            return {
                'comment_trend': {
                    'overall_change': comment_counts[-1] - comment_counts[0],
                    'peak_month': months[comment_counts.index(max(comment_counts))],
                    'peak_count': max(comment_counts),
                    'volatility': np.std(comment_counts)
                },
                'sentiment_trend': {
                    'positive_overall_change': positive_ratios[-1] - positive_ratios[0],
                    'negative_overall_change': negative_ratios[-1] - negative_ratios[0],
                    'most_positive_month': months[positive_ratios.index(max(positive_ratios))],
                    'most_negative_month': months[negative_ratios.index(max(negative_ratios))]
                },
                'significant_changes': significant_changes
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ì‹œê°„ì  ë³€í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {'error': str(e)}
    
    def _extract_key_findings(self, all_results: Dict, target_name: str) -> List[str]:
        """ì£¼ìš” ë°œê²¬ì‚¬í•­ ì¶”ì¶œ"""
        try:
            findings = []
            
            # ê°ì„± ë¶„ì„ ë°œê²¬ì‚¬í•­
            sentiment_summary = self._summarize_sentiment_analysis(all_results)
            if 'overall_statistics' in sentiment_summary:
                stats = sentiment_summary['overall_statistics']
                
                if stats['positive_ratio'] > 0.6:
                    findings.append(f"{target_name}ì— ëŒ€í•œ ì „ë°˜ì ì¸ ì—¬ë¡ ì€ ê¸ì •ì ì…ë‹ˆë‹¤ ({stats['positive_ratio']:.1%} ê¸ì •).")
                elif stats['negative_ratio'] > 0.6:
                    findings.append(f"{target_name}ì— ëŒ€í•œ ì „ë°˜ì ì¸ ì—¬ë¡ ì€ ë¶€ì •ì ì…ë‹ˆë‹¤ ({stats['negative_ratio']:.1%} ë¶€ì •).")
                else:
                    findings.append(f"{target_name}ì— ëŒ€í•œ ì—¬ë¡ ì€ ê¸ì •ê³¼ ë¶€ì •ì´ í˜¼ì¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                
                findings.append(f"ì£¼ìš” ê°ì •ì€ '{stats['dominant_emotion']}'ì…ë‹ˆë‹¤.")
            
            # ì‹œê°„ì  ë³€í™” ë°œê²¬ì‚¬í•­
            temporal_analysis = self._analyze_temporal_changes(all_results)
            if 'significant_changes' in temporal_analysis:
                significant_events = temporal_analysis['significant_changes']
                if significant_events:
                    findings.append(f"ë¶„ì„ ê¸°ê°„ ì¤‘ {len(significant_events)}ê°œì˜ ì£¼ìš” ë³€í™” ì‹œì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                    # ê°€ì¥ í° ë³€í™” ì‹œì 
                    if any(event['type'] == 'ëŒ“ê¸€ ìˆ˜ ê¸‰ì¦' for event in significant_events):
                        findings.append("íŠ¹ì • ì‹œì ì—ì„œ ëŒ“ê¸€ ìˆ˜ê°€ ê¸‰ì¦í•˜ì—¬ ë†’ì€ ê´€ì‹¬ë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.")
                    
                    if any(event['type'] == 'ê°ì„± ê¸‰ë³€' for event in significant_events):
                        findings.append("ê°ì„±ì´ ê¸‰ê²©íˆ ë³€í™”í•œ ì‹œì ë“¤ì´ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # í† í”½ ë¶„ì„ ë°œê²¬ì‚¬í•­
            topic_summary = self._summarize_topic_analysis(all_results)
            if 'bertopic_analysis' in topic_summary and 'lda_analysis' in topic_summary:
                bertopic_avg = topic_summary['bertopic_analysis']['avg_topics_per_month']
                lda_avg = topic_summary['lda_analysis']['avg_topics_per_month']
                
                if bertopic_avg > 5 or lda_avg > 5:
                    findings.append("ë‹¤ì–‘í•œ ì£¼ì œë“¤ì´ ë…¼ì˜ë˜ê³  ìˆì–´ ë³µí•©ì ì¸ ë‹´ë¡  êµ¬ì¡°ë¥¼ ë³´ì…ë‹ˆë‹¤.")
                else:
                    findings.append("ìƒëŒ€ì ìœ¼ë¡œ ì§‘ì¤‘ëœ ì£¼ì œ ë…¼ì˜ê°€ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.")
            
            # ì—°êµ¬ í•¨ì˜
            findings.append(f"ì´ëŸ¬í•œ ê²°ê³¼ëŠ” {target_name} ê´€ë ¨ ë‰´ìŠ¤ ë³´ë„ë§Œìœ¼ë¡œëŠ” íŒŒì•…í•˜ê¸° ì–´ë ¤ìš´ ì‹¤ì œ ëŒ€ì¤‘ ì—¬ë¡ ì˜ ë³µì¡ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")
            findings.append("ì‹œê°„ì— ë”°ë¥¸ ì—¬ë¡  ë³€í™”ëŠ” ë‹¨ìˆœí•œ ë‰´ìŠ¤ í”„ë ˆì„ì„ ë„˜ì–´ì„  ë‹¤ì¸µì  ë‹´ë¡  êµ¬ì¡°ë¥¼ ì‹œì‚¬í•©ë‹ˆë‹¤.")
            
            return findings
            
        except Exception as e:
            self.logger.error(f"âŒ ì£¼ìš” ë°œê²¬ì‚¬í•­ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            return [f"ë°œê²¬ì‚¬í•­ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"]
    
    def _generate_research_implications(self, all_results: Dict, target_name: str) -> Dict:
        """ì—°êµ¬ í•¨ì˜ ìƒì„±"""
        try:
            implications = {
                'methodological': [
                    "ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„ì„ í†µí•´ ê¸°ì¡´ ë‰´ìŠ¤ í”„ë ˆì„ ì—°êµ¬ì˜ í•œê³„ë¥¼ ë³´ì™„í•  ìˆ˜ ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.",
                    "ì›”ë³„ ì‹œê°„ ë¶„ì„ì„ í†µí•´ ì—¬ë¡ ì˜ ë™ì  ë³€í™” ê³¼ì •ì„ ì¶”ì í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.",
                    "ì´ì§„ ê°ì„± ë¶„ì„ê³¼ ë‹¤ì¤‘ ê°ì • ë¶„ì„ì˜ ê²°í•©ìœ¼ë¡œ ë” ì •êµí•œ ê°ì • ë¶„ì„ì´ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤.",
                    "BERTopicê³¼ LDAì˜ ë¹„êµ ë¶„ì„ìœ¼ë¡œ í† í”½ ëª¨ë¸ë§ì˜ ì‹ ë¢°ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤."
                ],
                'theoretical': [
                    "ê³µì¤‘ì˜ ì‹¤ì œ ë°˜ì‘ì€ ì–¸ë¡  ë³´ë„ í”„ë ˆì„ê³¼ ìƒë‹¹í•œ ì°¨ì´ë¥¼ ë³´ì¼ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤.",
                    "ì†Œì…œ ë¯¸ë””ì–´ ë‹´ë¡ ì€ ì „í†µì ì¸ ë¯¸ë””ì–´ ë‹´ë¡ ë³´ë‹¤ ë” ë³µì¡í•˜ê³  ë‹¤ì¸µì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤.",
                    "ì‹œê°„ì  ë³€í™” ë¶„ì„ì€ ì—¬ë¡  í˜•ì„± ê³¼ì •ì˜ ë™ì  íŠ¹ì„±ì„ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.",
                    "ê°ì •ì  ë°˜ì‘ì˜ ë‹¤ì–‘ì„±ì€ ë‹¨ìˆœí•œ ì°¬ë°˜ êµ¬ì¡°ë¥¼ ë„˜ì–´ì„  ë³µí•©ì  ì—¬ë¡  êµ¬ì¡°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."
                ],
                'practical': [
                    "ì •ì±… ê²°ì •ìë“¤ì€ ë‰´ìŠ¤ ë³´ë„ë¿ë§Œ ì•„ë‹ˆë¼ ì‹¤ì œ ëŒ€ì¤‘ ë°˜ì‘ì„ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•©ë‹ˆë‹¤.",
                    "ìœ„ê¸° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ëµ ìˆ˜ë¦½ ì‹œ ì‹œê°„ì  ë³€í™” íŒ¨í„´ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.",
                    "ì†Œì…œ ë¯¸ë””ì–´ ë¶„ì„ì€ ì—¬ë¡  ì¡°ì‚¬ì˜ ë³´ì™„ì  ë„êµ¬ë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                    "ì‹¤ì‹œê°„ ê°ì • ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì„ ì œì  ëŒ€ì‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                ],
                'limitations': [
                    "ìœ íŠœë¸Œ ëŒ“ê¸€ì€ ì „ì²´ ì¸êµ¬ë¥¼ ëŒ€í‘œí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                    "ìµëª…ì„±ìœ¼ë¡œ ì¸í•œ ê·¹ë‹¨ì  ì˜ê²¬ì˜ ê³¼ëŒ€í‘œí˜„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.",
                    "ì•Œê³ ë¦¬ì¦˜ì— ì˜í•œ ëŒ“ê¸€ ë…¸ì¶œ í¸í–¥ì´ ê²°ê³¼ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                    "ê°ì„± ë¶„ì„ ëª¨ë¸ì˜ í•œêµ­ì–´ ì²˜ë¦¬ í•œê³„ê°€ ì¡´ì¬í•©ë‹ˆë‹¤."
                ]
            }
            
            return implications
            
        except Exception as e:
            self.logger.error(f"âŒ ì—°êµ¬ í•¨ì˜ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {'error': str(e)}
    
    def _generate_html_report(self, content: Dict, target_name: str) -> str:
        """HTML ë³´ê³ ì„œ ìƒì„±"""
        try:
            html_template = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ target_name }} ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„ ë³´ê³ ì„œ</title>
    <style>
        body { font-family: 'Malgun Gothic', sans-serif; line-height: 1.6; margin: 40px; }
        .header { text-align: center; border-bottom: 3px solid #333; padding-bottom: 20px; margin-bottom: 30px; }
        .section { margin-bottom: 30px; }
        .section h2 { color: #2c3e50; border-left: 4px solid #3498db; padding-left: 10px; }
        .section h3 { color: #34495e; margin-top: 20px; }
        .stats-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }
        .stat-card { background: #f8f9fa; padding: 15px; border-radius: 8px; text-align: center; }
        .stat-value { font-size: 24px; font-weight: bold; color: #2c3e50; }
        .stat-label { color: #7f8c8d; font-size: 14px; }
        .finding { background: #e8f5e8; padding: 10px; margin: 10px 0; border-left: 4px solid #27ae60; }
        .implication { background: #fff3cd; padding: 10px; margin: 10px 0; border-left: 4px solid #ffc107; }
        .limitation { background: #f8d7da; padding: 10px; margin: 10px 0; border-left: 4px solid #dc3545; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
        th { background-color: #f2f2f2; }
    </style>
</head>
<body>
    <div class="header">
        <h1>{{ target_name }} ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„ ë³´ê³ ì„œ</h1>
        <p>ë¶„ì„ì¼: {{ analysis_date }}</p>
        <p>ë¶„ì„ ê¸°ê°„: {{ analysis_period.start }} ~ {{ analysis_period.end }} ({{ analysis_period.total_months }}ê°œì›”)</p>
    </div>

    <div class="section">
        <h2>1. ë¶„ì„ ê°œìš”</h2>
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-value">{{ "{:,}".format(total_comments) }}</div>
                <div class="stat-label">ì´ ë¶„ì„ ëŒ“ê¸€ ìˆ˜</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{{ analysis_period.total_months }}</div>
                <div class="stat-label">ë¶„ì„ ê¸°ê°„ (ê°œì›”)</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{{ "{:.1%}".format(sentiment_summary.overall_statistics.positive_ratio) }}</div>
                <div class="stat-label">ì „ì²´ ê¸ì • ë¹„ìœ¨</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{{ sentiment_summary.overall_statistics.dominant_emotion }}</div>
                <div class="stat-label">ì£¼ìš” ê°ì •</div>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>2. ê°ì„± ë¶„ì„ ê²°ê³¼</h2>
        <h3>2.1 ì „ì²´ ê°ì„± ë¶„í¬</h3>
        <p>ë¶„ì„ ê¸°ê°„ ë™ì•ˆ {{ target_name }}ì— ëŒ€í•œ ì „ì²´ ëŒ“ê¸€ì˜ ê°ì„± ë¶„í¬ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:</p>
        <ul>
            <li>ê¸ì •ì  ëŒ“ê¸€: {{ "{:.1%}".format(sentiment_summary.overall_statistics.positive_ratio) }}</li>
            <li>ë¶€ì •ì  ëŒ“ê¸€: {{ "{:.1%}".format(sentiment_summary.overall_statistics.negative_ratio) }}</li>
            <li>ì£¼ìš” ê°ì •: {{ sentiment_summary.overall_statistics.dominant_emotion }}</li>
        </ul>

        <h3>2.2 ê°ì„± ë³€í™” íŠ¸ë Œë“œ</h3>
        {% if sentiment_summary.trend_analysis.positive_trend %}
        <p>ê¸ì • ê°ì„± íŠ¸ë Œë“œ: <strong>{{ sentiment_summary.trend_analysis.positive_trend }}</strong></p>
        <p>ë¶€ì • ê°ì„± íŠ¸ë Œë“œ: <strong>{{ sentiment_summary.trend_analysis.negative_trend }}</strong></p>
        {% endif %}
    </div>

    <div class="section">
        <h2>3. í† í”½ ë¶„ì„ ê²°ê³¼</h2>
        <h3>3.1 BERTopic ë¶„ì„</h3>
        <p>ì›”í‰ê·  í† í”½ ìˆ˜: {{ "{:.1f}".format(topic_summary.bertopic_analysis.avg_topics_per_month) }}ê°œ</p>
        
        <h3>3.2 LDA ë¶„ì„</h3>
        <p>ì›”í‰ê·  í† í”½ ìˆ˜: {{ "{:.1f}".format(topic_summary.lda_analysis.avg_topics_per_month) }}ê°œ</p>
        <p>í‰ê·  ì¼ê´€ì„± ì ìˆ˜: {{ "{:.3f}".format(topic_summary.lda_analysis.avg_coherence) }}</p>
    </div>

    <div class="section">
        <h2>4. ì‹œê°„ì  ë³€í™” ë¶„ì„</h2>
        {% if temporal_analysis.comment_trend %}
        <h3>4.1 ëŒ“ê¸€ ìˆ˜ ë³€í™”</h3>
        <p>ì „ì²´ ë³€í™”ëŸ‰: {{ "{:+,}".format(temporal_analysis.comment_trend.overall_change) }}ê°œ</p>
        <p>ìµœê³  ëŒ“ê¸€ ìˆ˜ ì›”: {{ temporal_analysis.comment_trend.peak_month }} ({{ "{:,}".format(temporal_analysis.comment_trend.peak_count) }}ê°œ)</p>
        
        <h3>4.2 ì£¼ìš” ë³€í™” ì‹œì </h3>
        {% for change in temporal_analysis.significant_changes %}
        <div class="finding">
            <strong>{{ change.month }}</strong>: {{ change.description }}
        </div>
        {% endfor %}
        {% endif %}
    </div>

    <div class="section">
        <h2>5. ì£¼ìš” ë°œê²¬ì‚¬í•­</h2>
        {% for finding in key_findings %}
        <div class="finding">{{ finding }}</div>
        {% endfor %}
    </div>

    <div class="section">
        <h2>6. ì—°êµ¬ í•¨ì˜</h2>
        <h3>6.1 ë°©ë²•ë¡ ì  í•¨ì˜</h3>
        {% for implication in research_implications.methodological %}
        <div class="implication">{{ implication }}</div>
        {% endfor %}

        <h3>6.2 ì´ë¡ ì  í•¨ì˜</h3>
        {% for implication in research_implications.theoretical %}
        <div class="implication">{{ implication }}</div>
        {% endfor %}

        <h3>6.3 ì‹¤ë¬´ì  í•¨ì˜</h3>
        {% for implication in research_implications.practical %}
        <div class="implication">{{ implication }}</div>
        {% endfor %}
    </div>

    <div class="section">
        <h2>7. ì—°êµ¬ í•œê³„</h2>
        {% for limitation in research_implications.limitations %}
        <div class="limitation">{{ limitation }}</div>
        {% endfor %}
    </div>

    <div class="section">
        <h2>8. ê²°ë¡ </h2>
        <p>ë³¸ ì—°êµ¬ëŠ” {{ target_name }} ê´€ë ¨ ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„ì„ í†µí•´ ê¸°ì¡´ ë‰´ìŠ¤ í”„ë ˆì„ ì—°êµ¬ì˜ í•œê³„ë¥¼ ë³´ì™„í•˜ê³ , 
        ì‹¤ì œ ëŒ€ì¤‘ ì—¬ë¡ ì˜ ë³µì¡ì„±ê³¼ ì‹œê°„ì  ë³€í™” ì–‘ìƒì„ ê·œëª…í–ˆìŠµë‹ˆë‹¤. 
        ì´ëŠ” ì†Œì…œ ë¯¸ë””ì–´ ì‹œëŒ€ì˜ ì—¬ë¡  ì—°êµ¬ì— ìƒˆë¡œìš´ ë°©ë²•ë¡ ì  ì ‘ê·¼ì„ ì œì‹œí•©ë‹ˆë‹¤.</p>
    </div>
</body>
</html>
            """
            
            template = Template(html_template)
            html_content = template.render(**content)
            
            # íŒŒì¼ ì €ì¥
            filename = f"{target_name}_comprehensive_report.html"
            filepath = os.path.join(self.output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            self.logger.info(f"âœ… HTML ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"âŒ HTML ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _generate_markdown_report(self, content: Dict, target_name: str) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„±"""
        try:
            md_content = f"""# {content['target_name']} ìœ íŠœë¸Œ ëŒ“ê¸€ ë¶„ì„ ë³´ê³ ì„œ

**ë¶„ì„ì¼**: {content['analysis_date']}  
**ë¶„ì„ ê¸°ê°„**: {content['analysis_period']['start']} ~ {content['analysis_period']['end']} ({content['analysis_period']['total_months']}ê°œì›”)

## 1. ë¶„ì„ ê°œìš”

- **ì´ ë¶„ì„ ëŒ“ê¸€ ìˆ˜**: {content['total_comments']:,}ê°œ
- **ë¶„ì„ ê¸°ê°„**: {content['analysis_period']['total_months']}ê°œì›”
- **ì „ì²´ ê¸ì • ë¹„ìœ¨**: {content['sentiment_summary']['overall_statistics']['positive_ratio']:.1%}
- **ì£¼ìš” ê°ì •**: {content['sentiment_summary']['overall_statistics']['dominant_emotion']}

## 2. ê°ì„± ë¶„ì„ ê²°ê³¼

### 2.1 ì „ì²´ ê°ì„± ë¶„í¬
- ê¸ì •ì  ëŒ“ê¸€: {content['sentiment_summary']['overall_statistics']['positive_ratio']:.1%}
- ë¶€ì •ì  ëŒ“ê¸€: {content['sentiment_summary']['overall_statistics']['negative_ratio']:.1%}
- ì£¼ìš” ê°ì •: {content['sentiment_summary']['overall_statistics']['dominant_emotion']}

## 3. ì£¼ìš” ë°œê²¬ì‚¬í•­

"""
            
            for i, finding in enumerate(content['key_findings'], 1):
                md_content += f"{i}. {finding}\n"
            
            md_content += "\n## 4. ì—°êµ¬ í•¨ì˜\n\n"
            md_content += "### ë°©ë²•ë¡ ì  í•¨ì˜\n"
            for implication in content['research_implications']['methodological']:
                md_content += f"- {implication}\n"
            
            md_content += "\n### ì´ë¡ ì  í•¨ì˜\n"
            for implication in content['research_implications']['theoretical']:
                md_content += f"- {implication}\n"
            
            # íŒŒì¼ ì €ì¥
            filename = f"{target_name}_report.md"
            filepath = os.path.join(self.output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            self.logger.info(f"âœ… ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"âŒ ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _convert_numpy_types(self, obj):
        """numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
        import numpy as np
        
        if isinstance(obj, dict):
            return {str(k): self._convert_numpy_types(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_numpy_types(item) for item in obj]
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif hasattr(obj, 'item'):  # numpy scalar
            return obj.item()
        else:
            return obj
    
    def _generate_json_summary(self, all_results: Dict, target_name: str) -> str:
        """JSON ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        try:
            summary = {
                'target_name': target_name,
                'analysis_date': datetime.now().isoformat(),
                'total_comments': sum(result.get('total_comments', 0) for result in all_results.values()),
                'analysis_period': {
                    'start': min(all_results.keys()) if all_results else None,
                    'end': max(all_results.keys()) if all_results else None,
                    'total_months': len(all_results)
                },
                'monthly_results': all_results
            }
            
            # numpy íƒ€ì… ë³€í™˜
            summary = self._convert_numpy_types(summary)
            
            # íŒŒì¼ ì €ì¥
            filename = f"{target_name}_analysis_summary.json"
            filepath = os.path.join(self.output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"âœ… JSON ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"âŒ JSON ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise 